{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"include_colab_link":true},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":218074,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":185968,"modelId":208088}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/sAndreotti/MedicalMeadow/blob/main/ATML_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"Import Libraries","metadata":{"id":"29nxqgohSsQ3"}},{"cell_type":"code","source":"!pip install datasets accelerate peft bitsandbytes transformers trl==0.12.0 plotly huggingface_hub\n!pip install --upgrade smart_open\n!pip install --upgrade gensim\n!pip install ffmpeg-python\n!pip install -U openai-whisper\n!pip install scipy librosa unidecode inflect","metadata":{"id":"SAho3HGib9-U","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:06:28.982209Z","iopub.execute_input":"2025-01-07T09:06:28.982626Z","iopub.status.idle":"2025-01-07T09:06:48.427120Z","shell.execute_reply.started":"2025-01-07T09:06:28.982596Z","shell.execute_reply":"2025-01-07T09:06:48.426112Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\nRequirement already satisfied: trl==0.12.0 in /usr/local/lib/python3.10/dist-packages (0.12.0)\nRequirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl==0.12.0) (13.8.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl==0.12.0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl==0.12.0) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.12.0) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: smart_open in /usr/local/lib/python3.10/dist-packages (7.1.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart_open) (1.16.0)\nRequirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\nRequirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\nRequirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\nRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.1.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\nRequirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\nRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\nRequirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\nRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.1+cu121)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\nRequirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\nRequirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\nRequirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.8)\nRequirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (7.4.0)\nRequirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\nRequirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\nRequirement already satisfied: more-itertools>=8.5.0 in /usr/local/lib/python3.10/dist-packages (from inflect) (10.5.0)\nRequirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from inflect) (4.3.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"from datasets import load_dataset\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom collections import Counter\nfrom trl import SFTTrainer\nimport re\nfrom gensim.models.word2vec import Word2Vec\nimport plotly.express as px\nimport random\nfrom sklearn.manifold import TSNE\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import random_split\nfrom peft import prepare_model_for_kbit_training, LoraConfig\nfrom huggingface_hub import login\nimport torch\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    BitsAndBytesConfig,\n    TrainingArguments\n)\nfrom datasets import Dataset as HFDataset\nfrom peft import AutoPeftModelForCausalLM\nimport whisper\nfrom IPython.display import Audio","metadata":{"id":"q_JimYqjjY4S","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:06:48.428562Z","iopub.execute_input":"2025-01-07T09:06:48.428882Z","iopub.status.idle":"2025-01-07T09:06:48.434849Z","shell.execute_reply.started":"2025-01-07T09:06:48.428858Z","shell.execute_reply":"2025-01-07T09:06:48.433986Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## Investigate Dataset","metadata":{"id":"XKL46PcIc21t"}},{"cell_type":"code","source":"ds = load_dataset(\"medalpaca/medical_meadow_medical_flashcards\")\nds = ds['train']\nds","metadata":{"id":"YltBm7i4b0IM","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:06:48.436501Z","iopub.execute_input":"2025-01-07T09:06:48.436764Z","iopub.status.idle":"2025-01-07T09:06:49.259898Z","shell.execute_reply.started":"2025-01-07T09:06:48.436745Z","shell.execute_reply":"2025-01-07T09:06:49.259089Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input', 'output', 'instruction'],\n    num_rows: 33955\n})"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"print(ds.features, \"\\n\")\nprint(\"Instruction:\")\nprint(f\"length: {len(ds['instruction'])}\")\nprint(f\"example: {ds['instruction'][0]} \\n\")\n\nprint(f\"Input:\")\nprint(f\"length: {len(ds['input'])}\")\nprint(f\"example: {ds['input'][0]} \\n\")\n\nprint(f\"Output:\")\nprint(f\"length: {len(ds['output'])}\")\nprint(f\"example: {ds['output'][0]} \\n\")","metadata":{"id":"n89RynbpcHQB","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:06:49.261506Z","iopub.execute_input":"2025-01-07T09:06:49.261806Z","iopub.status.idle":"2025-01-07T09:06:49.484328Z","shell.execute_reply.started":"2025-01-07T09:06:49.261780Z","shell.execute_reply":"2025-01-07T09:06:49.483581Z"}},"outputs":[{"name":"stdout","text":"{'input': Value(dtype='string', id=None), 'output': Value(dtype='string', id=None), 'instruction': Value(dtype='string', id=None)} \n\nInstruction:\nlength: 33955\nexample: Answer this question truthfully \n\nInput:\nlength: 33955\nexample: What is the relationship between very low Mg2+ levels, PTH levels, and Ca2+ levels? \n\nOutput:\nlength: 33955\nexample: Very low Mg2+ levels correspond to low PTH levels which in turn results in low Ca2+ levels. \n\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"### Some plots about the dataset","metadata":{"id":"a9SXu1UFoE4x"}},{"cell_type":"code","source":"instructions = ds['instruction']\ninput_phrases = ds['input']\noutput_phrases = ds['output']","metadata":{"trusted":true,"id":"nLEtHKtISsQ7","execution":{"iopub.status.busy":"2025-01-07T09:06:49.485134Z","iopub.execute_input":"2025-01-07T09:06:49.485391Z","iopub.status.idle":"2025-01-07T09:06:49.600771Z","shell.execute_reply.started":"2025-01-07T09:06:49.485368Z","shell.execute_reply":"2025-01-07T09:06:49.600006Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"## Train and evaluate models","metadata":{"id":"-BMh1vbuc5qp"}},{"cell_type":"markdown","source":"#### Create dataset","metadata":{"id":"VFt5KLR-8w3p"}},{"cell_type":"code","source":"class MedDataset(Dataset):\n    def __init__(self, dataset, tokenizer):\n        self.dataset = dataset\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        example = self.dataset[idx]\n        messages = [\n            {\"role\": \"system\", \"content\": example['instruction']},\n            {\"role\": \"user\", \"content\": example['input']},\n            {\"role\": \"assistant\", \"content\": example['output']}\n        ]\n\n        prompt = self.tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=True\n        )\n\n        tokens = self.tokenizer(\n            prompt,\n            padding=\"max_length\",\n            truncation=True,\n            max_length=128,\n            return_tensors=\"pt\"\n        )\n\n        tokens['labels'] = tokens['input_ids'].clone()\n        tokens['labels'][tokens['input_ids'] == self.tokenizer.pad_token_id] = -100\n\n        return {\n            \"input_ids\": tokens['input_ids'].squeeze(),\n            \"attention_mask\": tokens['attention_mask'].squeeze(),\n            \"labels\": tokens['labels'].squeeze()\n        }","metadata":{"trusted":true,"id":"LacKbkPHSsQ-","execution":{"iopub.status.busy":"2025-01-07T09:06:49.601605Z","iopub.execute_input":"2025-01-07T09:06:49.601808Z","iopub.status.idle":"2025-01-07T09:06:49.612445Z","shell.execute_reply.started":"2025-01-07T09:06:49.601791Z","shell.execute_reply":"2025-01-07T09:06:49.611755Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"login(token=\"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\")\n\nbase_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n\ntokenizer = AutoTokenizer.from_pretrained(base_model)\ntokenizer.pad_token = tokenizer.eos_token\n\n# tokenizer.padding_side = \"right\"","metadata":{"trusted":true,"id":"AelKMq1xSsQ-","execution":{"iopub.status.busy":"2025-01-07T09:06:49.613320Z","iopub.execute_input":"2025-01-07T09:06:49.613616Z","iopub.status.idle":"2025-01-07T09:06:50.264235Z","shell.execute_reply.started":"2025-01-07T09:06:49.613586Z","shell.execute_reply":"2025-01-07T09:06:50.263574Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"train_dataset, val_dataset, test_dataset = random_split(ds, [0.8, 0.1, 0.1])\n\ntrain_dataset = MedDataset(train_dataset, tokenizer)\nval_dataset = MedDataset(val_dataset, tokenizer)\n\nprint(f\"Train dataset dimension: {len(train_dataset)}\")\nprint(f\"Validation dataset dimension: {len(val_dataset)}\")\nprint(f\"Test dataset dimension: {len(test_dataset)}\")","metadata":{"id":"RRneCjBj9Lag","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:06:50.266438Z","iopub.execute_input":"2025-01-07T09:06:50.266665Z","iopub.status.idle":"2025-01-07T09:06:50.274986Z","shell.execute_reply.started":"2025-01-07T09:06:50.266646Z","shell.execute_reply":"2025-01-07T09:06:50.274187Z"}},"outputs":[{"name":"stdout","text":"Train dataset dimension: 27165\nValidation dataset dimension: 3395\nTest dataset dimension: 3395\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\n\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_representation=\"nested\"\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=quant_config,\n    device_map={\"\": 0},\n    torch_dtype=torch.float32,\n    trust_remote_code=True\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"id":"gR4BtF8AHD0I","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:06:50.277581Z","iopub.execute_input":"2025-01-07T09:06:50.277797Z","iopub.status.idle":"2025-01-07T09:06:54.906026Z","shell.execute_reply.started":"2025-01-07T09:06:50.277777Z","shell.execute_reply":"2025-01-07T09:06:54.905147Z"}},"outputs":[{"name":"stderr","text":"Unused kwargs: ['bnb_4bit_representation']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# def convert_to_hf_dataset(med_dataset):\n#     # Create lists to store all formatted text\n#     formatted_texts = []\n\n#     # Iterate through all items in the original dataset\n#     for idx in range(len(med_dataset.instruction)):\n#         # Get the formatted text directly using the dataset's __getitem__\n#         formatted_text = med_dataset[idx]\n#         formatted_texts.append(formatted_text)\n\n#     # Create a dictionary with the required format\n#     dataset_dict = {\n#         'text': formatted_texts\n#     }\n\n#     # Convert to HuggingFace Dataset\n#     hf_dataset = HFDataset.from_dict(dataset_dict)\n\n#     return hf_dataset\n\n# hf_dataset = convert_to_hf_dataset(garnachoDataset)","metadata":{"id":"gzL6yXsGSsQ_","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:06:54.907438Z","iopub.execute_input":"2025-01-07T09:06:54.907679Z","iopub.status.idle":"2025-01-07T09:06:54.910868Z","shell.execute_reply.started":"2025-01-07T09:06:54.907658Z","shell.execute_reply":"2025-01-07T09:06:54.910068Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"peft_params = LoraConfig(\n    lora_alpha=32,\n    lora_dropout=0.1,\n    r=16,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"id":"ew98HuwaKW1P","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:06:54.911615Z","iopub.execute_input":"2025-01-07T09:06:54.911812Z","iopub.status.idle":"2025-01-07T09:06:54.923412Z","shell.execute_reply.started":"2025-01-07T09:06:54.911795Z","shell.execute_reply":"2025-01-07T09:06:54.922572Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"model.train()\ntraining_params = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=4,\n    optim=\"paged_adamw_32bit\",\n    eval_strategy=\"steps\",\n    logging_steps=90,\n    eval_steps = 90,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n    report_to=\"tensorboard\",\n    gradient_checkpointing=True\n)","metadata":{"id":"n8dBHX-j-M1J","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:06:54.924202Z","iopub.execute_input":"2025-01-07T09:06:54.924425Z","iopub.status.idle":"2025-01-07T09:06:54.963495Z","shell.execute_reply.started":"2025-01-07T09:06:54.924405Z","shell.execute_reply":"2025-01-07T09:06:54.962697Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# trainer = SFTTrainer(\n#     model=model,\n#     train_dataset=train_dataset,\n#     eval_dataset=val_dataset,\n#     peft_config=peft_params,\n#     max_seq_length=256,\n#     tokenizer=tokenizer,\n#     args=training_params,\n#     packing=False,\n# )\n\n# # Train the model\n# trainer.train()\n\n# # Save the model and tokenizer\n# trainer.save_model(\"./fine-tuned-model\")\n# tokenizer.save_pretrained(\"./fine-tuned-model\")","metadata":{"trusted":true,"id":"ARnpWrEFSsQ_","execution":{"iopub.status.busy":"2025-01-07T09:06:54.964423Z","iopub.execute_input":"2025-01-07T09:06:54.964704Z","iopub.status.idle":"2025-01-07T09:06:54.967799Z","shell.execute_reply.started":"2025-01-07T09:06:54.964676Z","shell.execute_reply":"2025-01-07T09:06:54.967120Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# trainer.model.save_pretrained(\"model-chatbot-medical-mew\")\n# trainer.tokenizer.save_pretrained(\"model-chatbot-medical-mew\")","metadata":{"id":"awbFBy8v5rDM","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:06:54.968545Z","iopub.execute_input":"2025-01-07T09:06:54.968754Z","iopub.status.idle":"2025-01-07T09:06:54.978649Z","shell.execute_reply.started":"2025-01-07T09:06:54.968735Z","shell.execute_reply":"2025-01-07T09:06:54.977933Z"}},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"## Test Trained Model","metadata":{"id":"MmC39wTYSsQ_"}},{"cell_type":"markdown","source":"### Load pre-trained model","metadata":{"id":"UwQNV8XLYoLX"}},{"cell_type":"code","source":"trained_model = \"/kaggle/input/medicalllm/pytorch/default/1/model-chatbot-medical-mew\"\nquestion = \"What does low Mobility suggest?\"\n\nmodel = AutoPeftModelForCausalLM.from_pretrained(\n    trained_model, # change with folder where u have the files\n    quantization_config=quant_config,\n    device_map={\"\": 0},\n    torch_dtype=torch.float32,\n    trust_remote_code=True\n)\ntokenizer = AutoTokenizer.from_pretrained(trained_model)","metadata":{"id":"A-XhCQC1YhLP","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:06:54.979370Z","iopub.execute_input":"2025-01-07T09:06:54.979584Z","iopub.status.idle":"2025-01-07T09:07:00.880513Z","shell.execute_reply.started":"2025-01-07T09:06:54.979546Z","shell.execute_reply":"2025-01-07T09:07:00.879566Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"messages = [{\"role\": \"system\", \"content\": instructions[0]},\n    {\"role\": \"user\", \"content\": question}]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n\nmodel_inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\noutputs = model.generate(**model_inputs, max_new_tokens=128)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(f\"Question: {question}\")\nprint(text.split(\"assistant\")[1])","metadata":{"trusted":true,"id":"NL-rYUPJSsRD","execution":{"iopub.status.busy":"2025-01-07T09:07:00.881495Z","iopub.execute_input":"2025-01-07T09:07:00.881741Z","iopub.status.idle":"2025-01-07T09:07:01.550377Z","shell.execute_reply.started":"2025-01-07T09:07:00.881719Z","shell.execute_reply":"2025-01-07T09:07:01.549610Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Question: What does low Mobility suggest?\n\n\nLow mobility may suggest a condition such as osteoporosis or atherosclerosis.\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"### Compare with MedLlama","metadata":{}},{"cell_type":"code","source":"# Prima disinstalliamo e reinstalliamo bitsandbytes per sicurezza\n!pip uninstall -y bitsandbytes\n!pip install bitsandbytes\n!pip install accelerate transformers\n\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport logging","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:07:01.551158Z","iopub.execute_input":"2025-01-07T09:07:01.551398Z","iopub.status.idle":"2025-01-07T09:07:10.822116Z","shell.execute_reply.started":"2025-01-07T09:07:01.551376Z","shell.execute_reply":"2025-01-07T09:07:10.821214Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Found existing installation: bitsandbytes 0.45.0\nUninstalling bitsandbytes-0.45.0:\n  Successfully uninstalled bitsandbytes-0.45.0\nCollecting bitsandbytes\n  Using cached bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.1+cu121)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\nUsing cached bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\nInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.0\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.27.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"def setup_medAlpaca():   \n    try:\n        # bits and bytes version\n        import bitsandbytes as bnb\n        print(f\"bitsandbytes version: {bnb.__version__}\")\n        \n        # device\n        print(f\"CUDA available: {torch.cuda.is_available()}\")\n        if torch.cuda.is_available():\n            print(f\"CUDA version: {torch.version.cuda}\")\n        \n        # try not quantize model\n        model = AutoModelForCausalLM.from_pretrained(\n            \"medalpaca/medalpaca-7b\",\n            trust_remote_code=True,\n            device_map='auto',\n            torch_dtype=torch.float16\n        )\n        \n        tokenizer = AutoTokenizer.from_pretrained(\"medalpaca/medalpaca-7b\")\n        \n        return model, tokenizer\n        \n    except Exception as e:\n        print(f\"Si è verificato un errore: {str(e)}\")\n        print(\"\\nInformazioni di debug:\")\n        print(f\"Python version: {sys.version}\")\n        if torch.cuda.is_available():\n            print(f\"GPU: {torch.cuda.get_device_name()}\")\n        return None, None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:07:10.823334Z","iopub.execute_input":"2025-01-07T09:07:10.823659Z","iopub.status.idle":"2025-01-07T09:07:10.829723Z","shell.execute_reply.started":"2025-01-07T09:07:10.823630Z","shell.execute_reply":"2025-01-07T09:07:10.828890Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Esecuzione\nmodelMED, tokenizerMED = setup_medAlpaca()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:07:10.830594Z","iopub.execute_input":"2025-01-07T09:07:10.830886Z","iopub.status.idle":"2025-01-07T09:09:03.631025Z","shell.execute_reply.started":"2025-01-07T09:07:10.830857Z","shell.execute_reply":"2025-01-07T09:09:03.630305Z"}},"outputs":[{"name":"stdout","text":"bitsandbytes version: 0.45.0\nCUDA available: True\nCUDA version: 12.1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:606: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pad_token_id` explicitly as `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b8f2c666fb446a8a99d5d1440de8373"}},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"# tokenizerMED = AutoTokenizer.from_pretrained(\"OpenScienceReseach/Med-LLaMA-7b\")\n# modelMED = AutoModelForCausalLM.from_pretrained(\"OpenScienceReseach/Med-LLaMA-7b\") funzia ma lento\n\n# tokenizerMED = AutoTokenizer.from_pretrained(\"medalpaca/medalpaca-7b\")\n# modelMED = AutoModelForCausalLM.from_pretrained(\"medalpaca/medalpaca-7b\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:09:03.634889Z","iopub.execute_input":"2025-01-07T09:09:03.635121Z","iopub.status.idle":"2025-01-07T09:09:03.638517Z","shell.execute_reply.started":"2025-01-07T09:09:03.635102Z","shell.execute_reply":"2025-01-07T09:09:03.637607Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"!pip install nltk\nimport nltk\nnltk.download('punkt')\n\nfrom nltk.translate.bleu_score import sentence_bleu\n\n# BLUE score between the candiate (generate answer) and the reference answer\ndef calculate_bleu(reference, candidate):\n    try:\n      score = sentence_bleu(reference, candidate)\n      return score\n    except Exception as e:\n      print(f\"Error during BLUE computing: {e}\")\n      return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:09:03.639325Z","iopub.execute_input":"2025-01-07T09:09:03.639595Z","iopub.status.idle":"2025-01-07T09:09:06.881356Z","shell.execute_reply.started":"2025-01-07T09:09:03.639568Z","shell.execute_reply":"2025-01-07T09:09:06.880317Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.16.0)\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"test_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:09:06.882437Z","iopub.execute_input":"2025-01-07T09:09:06.882673Z","iopub.status.idle":"2025-01-07T09:09:06.894339Z","shell.execute_reply.started":"2025-01-07T09:09:06.882653Z","shell.execute_reply":"2025-01-07T09:09:06.893569Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"{'input': 'What is the mechanism responsible for the expression of tissue-restricted self-antigens in the thymus for negative selection, and what is the name of the protein that mediates this mechanism?',\n 'output': 'The mechanism responsible for the expression of tissue-restricted self-antigens in the thymus for negative selection is mediated by the autoimmune regulator (AIRE) protein. AIRE is responsible for inducing the expression of tissue-specific antigens in thymic epithelial cells, which is important for the development of self-tolerance and prevention of autoimmune diseases.',\n 'instruction': 'Answer this question truthfully'}"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"test = test_dataset[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:09:06.895275Z","iopub.execute_input":"2025-01-07T09:09:06.895595Z","iopub.status.idle":"2025-01-07T09:09:06.917225Z","shell.execute_reply.started":"2025-01-07T09:09:06.895566Z","shell.execute_reply":"2025-01-07T09:09:06.916511Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# questions = [\"What does low REM sleep latency and experiencing hallucinations/sleep paralysis suggest?\",\n#              \"What are some possible causes of low PTH and high calcium levels?\",\n#              \"What is the term used to describe a condition of low sodium levels and very high proteins or lipids?\"]\n\n# dataset_answer = [\"Low REM sleep latency and experiencing hallucinations/sleep paralysis suggests narcolepsy.\",\n#                   \"PTH-independent hypercalcemia, which can be caused by cancer, granulomatous disease, or vitamin D intoxication.\",\n#                   \"The term used to describe a condition of low sodium levels and very high proteins or lipids is pseudohyponatremia.\"]\n\nalpaca_bleu = []\nour_bleu = []\n\nfrom transformers import pipeline\nimport time\nimport re\n\ninstruction = \"Answer this question truthfully: \"\n\n# medAlpaca\nprint(\"MedAlpaca\")\nfor i, question in enumerate(test['input']):\n    print(f\"\\nQuestion: {question}\")\n    \n    input_text = instruction + question\n\n    # generate response\n    input_ids = tokenizerMED(input_text, return_tensors='pt').to(modelMED.device)[\"input_ids\"]\n    outputs = modelMED.generate(input_ids, max_new_tokens=128)\n    response = tokenizerMED.decode(outputs[0])\n    clean_response = re.sub(r'.*?\\? ', '', response, flags=re.DOTALL)\n    \n    print(\"   Response MedAlpaca:\", clean_response)\n\n    # blue score\n    candidate = clean_response.split()\n    bleu_score = calculate_bleu(test['output'][i], candidate)\n\n    if bleu_score is not None:\n        print(f\"BLEU score for Llama answer {i}: {bleu_score}\")   \n        alpaca_bleu.append(bleu_score)\n\nprint(\"\\nMedical Meadow\")\n# medical meadow\nfor i, question in enumerate(test['input']):\n    print(f\"\\nQuestion: {question}\")\n    \n    # generate response\n    messages = [{\"role\": \"system\", \"content\": instructions[0]},\n    {\"role\": \"user\", \"content\": question}]\n    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    model_inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n    outputs = model.generate(**model_inputs, max_new_tokens=128)\n    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    our = text.split(\"assistant\")[1]\n    \n    print(\"Response Medical Meadow: \", our)\n\n    # bleu score\n    candidate = our.split()\n    bleu_score = calculate_bleu(test['output'][i], candidate)\n\n    if bleu_score is not None:\n        print(f\"BLEU score for Medical Meadow answer {i}: {bleu_score}\")   \n        our_bleu.append(bleu_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:15:41.617966Z","iopub.execute_input":"2025-01-07T09:15:41.618304Z","iopub.status.idle":"2025-01-07T09:16:09.743925Z","shell.execute_reply.started":"2025-01-07T09:15:41.618259Z","shell.execute_reply":"2025-01-07T09:16:09.743242Z"}},"outputs":[{"name":"stdout","text":"MedAlpaca\n\nQuestion: What is the mechanism responsible for the expression of tissue-restricted self-antigens in the thymus for negative selection, and what is the name of the protein that mediates this mechanism?\n   Response MedAlpaca: The mechanism responsible for the expression of tissue-restricted self-antigens in the thym\nBLEU score for Llama answer 0: 0\n\nQuestion: What type of organisms do 1st generation cephalosporins have activity mostly against?\n   Response MedAlpaca: Gram positive organisms.</s><s>\nBLEU score for Llama answer 1: 0\n\nQuestion: What are some of the metabolic abnormalities associated with von Gierke disease?\n   Response MedAlpaca: </s> Answer this question truthfully: What are some of the metabolic abnormalities associated with von Gierke disease?\n\nThe metabolic abnormalities associated with von Gierke disease include increased levels of lactate, glucose, and lipids in the blood.</s><s>\nBLEU score for Llama answer 2: 0\n\nQuestion: What factor most stimulates gastrin secretion in the stomach?\n   Response MedAlpaca: </s> Answer this question truthfully: What factor most stimulates gastrin secretion in the stomach?\n\nThe most potent stimulant of gastrin secretion is the presence of food in the stomach.</s><s>\nBLEU score for Llama answer 3: 0\n\nQuestion: What is the primary use of etanercept, and what condition is it used to treat?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"   Response MedAlpaca: Etanercept is a medication that is primarily used to treat Rheumatoid Arthritis.</s><s>\nBLEU score for Llama answer 4: 0.537284965911771\n\nMedical Meadow\n\nQuestion: What is the mechanism responsible for the expression of tissue-restricted self-antigens in the thymus for negative selection, and what is the name of the protein that mediates this mechanism?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Response Medical Meadow:  \n\nThe mechanism responsible for the expression of tissue-restricted self-antigens in the thymus for negative selection is mediated by the TCRγβ (CD161) protein. TCRγβ is a receptor that is expressed on the surface of T cells and helps to distinguish between self and non-self antigens. When T cells encounter self-antigens, TCRγβ binds to them and activates a signaling cascade that promotes their differentiation into a regulatory T cell, which is then deleted from the thymus. This process helps to prevent T cells from attacking self-antigens and ensures that the immune system does\nBLEU score for Medical Meadow answer 0: 0.38503228868787126\n\nQuestion: What type of organisms do 1st generation cephalosporins have activity mostly against?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Response Medical Meadow:  \n\n1st generation cephalosporins have activity mostly against Gram-positive bacteria.\nBLEU score for Medical Meadow answer 1: 0\n\nQuestion: What are some of the metabolic abnormalities associated with von Gierke disease?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Response Medical Meadow:  \n\nVon Gierke disease is a metabolic disorder that is characterized by a deficiency of the enzyme glucose-6-phosphofructokinase, which is involved in the conversion of fructose-6-phosphate to glucose-6-phosphate. This leads to an accumulation of fructose-6-phosphate, which can cause a range of metabolic abnormalities, including:\n\n* Hyperglycemia (high blood sugar)\n* Hyperlipidemia (elevated cholesterol and triglycerides)\n* Lipid metabolism disorders\n* Hypoglycemia (low blood sugar)\n* Increased risk of developing fatty liver disease\n* High levels\nBLEU score for Medical Meadow answer 2: 0.34095107969299543\n\nQuestion: What factor most stimulates gastrin secretion in the stomach?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Response Medical Meadow:  \n\nGastrin secretion in the stomach is most stimulated by H2R2 receptors, which are located on the parietal cells of the stomach lining. When H2R2 receptors are activated by histamine, they send a signal to the parietal cells to secrete gastrin, which stimulates the release of gastric acid and digestive enzymes. This helps to break down food in the stomach and prepare it for further digestion in the small intestine.\nBLEU score for Medical Meadow answer 3: 0.346966645494591\n\nQuestion: What is the primary use of etanercept, and what condition is it used to treat?\nResponse Medical Meadow:  \n\nEtanercept is a monoclonal antibody that is primarily used to treat rheumatoid arthritis (RA) and psoriatic arthritis (PsA).\nBLEU score for Medical Meadow answer 4: 0.4854917717073234\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"from tabulate import tabulate\n\ntable = list(zip([0,1,2,3,4,5,6,7,8,9], alpaca_bleu, our_bleu))\nprint('BLEU score')\nprint(tabulate(table, headers=['Question', 'MedAlpaca', 'MedicalMeadow'], tablefmt='grid'))\n\nimport numpy\nbleu_alpaca = np.mean(alpaca_bleu)\nbleu_med = np.mean(our_bleu)\nprint(f\"\\n-> Average BLEU score for MedAlpaca model: {bleu_alpaca}\")\nprint(f\"-> Average BLEU score for MedicalMeadow model: {bleu_med}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T09:09:42.594089Z","iopub.execute_input":"2025-01-07T09:09:42.594502Z","iopub.status.idle":"2025-01-07T09:09:42.602189Z","shell.execute_reply.started":"2025-01-07T09:09:42.594462Z","shell.execute_reply":"2025-01-07T09:09:42.601402Z"}},"outputs":[{"name":"stdout","text":"BLEU score\n+------------+-------------+-----------------+\n|   Question |   MedAlpaca |   MedicalMeadow |\n+============+=============+=================+\n|          0 |    0        |        0.461737 |\n+------------+-------------+-----------------+\n|          1 |    0        |        0        |\n+------------+-------------+-----------------+\n|          2 |    0        |        0.321157 |\n+------------+-------------+-----------------+\n|          3 |    0.323772 |        0        |\n+------------+-------------+-----------------+\n|          4 |    0.326497 |        0.562341 |\n+------------+-------------+-----------------+\n\n-> Average BLEU score for MedAlpaca model: 0.1300538748354739\n-> Average BLEU score for MedicalMeadow model: 0.26904708650012193\n","output_type":"stream"}],"execution_count":54}]}