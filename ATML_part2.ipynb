{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"authorship_tag":"ABX9TyPo4GrctAvw9KTcspDzzKSL","include_colab_link":true},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/sAndreotti/MedicalMeadow/blob/main/ATML_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"!pip install datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SAho3HGib9-U","outputId":"38c3373b-2927-4c40-f724-97c4ea9fc735","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom collections import Counter","metadata":{"id":"q_JimYqjjY4S","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Investigate Dataset","metadata":{"id":"XKL46PcIc21t"}},{"cell_type":"code","source":"ds = load_dataset(\"medalpaca/medical_meadow_medical_flashcards\")\nds = ds['train']\nds","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YltBm7i4b0IM","outputId":"70bfdcf6-b5b5-410a-bc7c-74e279cf6bc2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(ds.features)\nprint()\n\nprint(\"Instruction:\")\nprint(f\"length: {len(ds['instruction'])}\")\nprint(f\"example: {ds['instruction'][0]}\")\nprint()\n\nprint(f\"Input:\")\nprint(f\"length: {len(ds['input'])}\")\nprint(f\"example: {ds['input'][0]}\")\nprint()\n\nprint(f\"Output:\")\nprint(f\"length: {len(ds['output'])}\")\nprint(f\"example: {ds['output'][0]}\")\nprint()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n89RynbpcHQB","outputId":"e9232f71-372c-40f0-9894-5d7e437b1c34","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Some plots about the dataset","metadata":{"id":"a9SXu1UFoE4x"}},{"cell_type":"code","source":"# Extract the 'instruction' field\ninstructions = ds['instruction']\n\n# Count the frequency of each unique instruction\ninstruction_counts = {instruction: instructions.count(instruction) for instruction in set(instructions)}\n\n# Sort the instructions by frequency\nsorted_instructions = sorted(instruction_counts.items(), key=lambda x: x[1], reverse=True)\n\n# Separate the instructions and their counts for plotting\nsorted_instruction_names = [item[0] for item in sorted_instructions]\nsorted_instruction_counts = [item[1] for item in sorted_instructions]\n\n# Plotting the frequency of instructions\nplt.figure(figsize=(10, 5))\n\nbars = plt.barh(sorted_instruction_names, sorted_instruction_counts, color='skyblue', edgecolor='black', linewidth=1.2)\nplt.title('Instruction Frequency Distribution')\nplt.xlabel('Frequency')\nplt.ylabel('Instruction')\n\n# Show the plot\nplt.tight_layout()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"id":"4TAMV5DdnRg7","outputId":"e9cd9424-5418-4639-c717-37c746ce0b23","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_phrases = ds['input']\noutput_phrases = ds['output']\n\n# Calculate the length of each phrase\ninput_lengths = [len(phrase) for phrase in input_phrases]\noutput_lengths = [len(phrase) for phrase in output_phrases]\n\n# Define the bins for the length ranges\nmax_input = max(input_lengths)\nmax_output = max(output_lengths)\n\ninput_bins = [i * max_input / 10 for i in range(1, 11)]\noutput_bins = [i * max_output / 10 for i in range(1, 11)]\nbin_labels_input = [f'{int(input_bins[i-1])}-{int(input_bins[i])}' for i in range(1, 10)]\nbin_labels_output = [f'{int(output_bins[i-1])}-{int(output_bins[i])}' for i in range(1, 10)]\n\n# Bin the lengths into the categories\ninput_binned = np.digitize(input_lengths, input_bins)  # Categorize based on input lengths\noutput_binned = np.digitize(output_lengths, output_bins)  # Categorize based on output lengths\n\n# Count how many phrases fall into each bin\ninput_bin_counts = [sum(input_binned == i) for i in range(1, len(input_bins))]\noutput_bin_counts = [sum(output_binned == i) for i in range(1, len(output_bins))]\n\n# Plotting the bar charts\nplt.figure(figsize=(20, 10))\n\n# Plotting the input phrase lengths\nplt.subplot(1, 2, 1)\nplt.bar(bin_labels_input, input_bin_counts, color='skyblue', edgecolor='black')\nplt.title('Input Phrases Length Distribution')\nplt.xlabel('Length Range')\nplt.ylabel('Number of Phrases')\n\n# Plotting the output phrase lengths\nplt.subplot(1, 2, 2)\nplt.bar(bin_labels_output, output_bin_counts, color='skyblue', edgecolor='black')\nplt.title('Output Phrases Length Distribution')\nplt.xlabel('Length Range')\nplt.ylabel('Number of Phrases')\n\n# Show the plots\nplt.tight_layout()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":815},"id":"d9lEMELsiqIx","outputId":"a3f2c5e7-92cb-474d-fc56-04aad79fb77e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tokenize","metadata":{}},{"cell_type":"code","source":"import re\n\n# merge in & out togheter\nmerged_list = [f\"{a} {b}\" for a, b in zip(input_phrases, output_phrases)]\n\n# remove newline characters\ndocs = [re.sub('\\n', ' ', doc) for doc in merged_list]\n# split sentences\nsentences = [re.split('[?!.]\\s', doc) for doc in docs]\nsentences[:3]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pandas.core.common import flatten\n\nsentences = list(flatten(sentences))\nsentences[:20]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_sentences = [re.sub('\\W', ' ', sentence).lower().split() for sentence in sentences]\n# remove sentences that are only 1 word long\ntokenized_sentences = [sentence for sentence in tokenized_sentences if len(sentence) > 1]\n\nfor sentence in tokenized_sentences[:5]:\n    print(sentence)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Word2Vec","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade smart_open\n!pip install --upgrade gensim","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from gensim.models.word2vec import Word2Vec\n\nmodel = Word2Vec(tokenized_sentences, vector_size=30, min_count=5, window=10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\nsample = random.sample(list(model.wv.key_to_index), 500)\nword_vectors = model.wv[sample]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3D plot with words","metadata":{}},{"cell_type":"code","source":"!pip install plotly\nimport plotly.express as px","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.manifold import TSNE\n\ntsne = TSNE(n_components=3, n_iter=2000)\ntsne_embedding = tsne.fit_transform(word_vectors)\n\nx, y, z = np.transpose(tsne_embedding)\n\nfig = px.scatter_3d(x=x[:200],y=y[:200],z=z[:200],text=sample[:200])\nfig.update_traces(marker=dict(size=3,line=dict(width=2)),textfont_size=10)\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"first_question = ['man', 'woman']\n#question = ['rem', 'sleep', 'hallucinations', 'paralysis']\n\nword_vectors = model.wv[first_question+sample]\n\ntsne = TSNE(n_components=3)\ntsne_embedding = tsne.fit_transform(word_vectors)\n\nx, y, z = np.transpose(tsne_embedding)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"r = (-200,200)\nfig = px.scatter_3d(x=x, y=y, z=z, range_x=r, range_y=r, range_z=r, text=first_question + [None] * 500)\nfig.update_traces(marker=dict(size=3,line=dict(width=2)),textfont_size=10)\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.wv.most_similar('menopause')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vec = model.wv.get_vector('headache') + (model.wv.get_vector('fever') - model.wv.get_vector('drug'))\nmodel.wv.similar_by_vector(vec)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train and evaluate models","metadata":{"id":"-BMh1vbuc5qp"}},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ntokenizer = AutoTokenizer.from_pretrained(\"decapoda-research/llama-3-70b-instruct-titan-0.1\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"decapoda-research/llama-3-70b-instruct-titan-0.1\",\n    device_map=\"cuda\",\n    torch_dtype=\"auto\",\n    trust_remote_code=True,\n)","metadata":{"id":"Ak2dRuLhdExx","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=ds,\n    peft_config=peft_params,\n    dataset_text_field=\"text\",\n    max_seq_length=None,\n    tokenizer=tokenizer,\n    args=training_params,\n    packing=False,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Add voice interactivity","metadata":{"id":"WALd3_Hvc9f1"}},{"cell_type":"code","source":"","metadata":{"id":"EIodhbikdF16","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Potential extensions","metadata":{"id":"MIYtSGoJdAkP"}},{"cell_type":"code","source":"","metadata":{"id":"h1mPCVNJdGSr","trusted":true},"outputs":[],"execution_count":null}]}