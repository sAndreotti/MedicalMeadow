{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"include_colab_link":true},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/sAndreotti/MedicalMeadow/blob/main/ATML_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"Import Libraries","metadata":{"id":"29nxqgohSsQ3"}},{"cell_type":"code","source":"!pip install datasets accelerate peft bitsandbytes transformers trl==0.12.0 plotly huggingface_hub\n!pip install --upgrade smart_open\n!pip install --upgrade gensim\n!pip install ffmpeg-python\n!pip install -U openai-whisper\n!pip install scipy librosa unidecode inflect","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:58:25.513090Z","iopub.status.busy":"2024-12-30T16:58:25.512794Z","iopub.status.idle":"2024-12-30T16:59:13.506495Z","shell.execute_reply":"2024-12-30T16:59:13.505543Z","shell.execute_reply.started":"2024-12-30T16:58:25.513052Z"},"id":"SAho3HGib9-U","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom collections import Counter\nfrom trl import SFTTrainer\nimport re\nfrom gensim.models.word2vec import Word2Vec\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport random\nfrom sklearn.manifold import TSNE\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import random_split\nfrom peft import prepare_model_for_kbit_training, LoraConfig\nfrom huggingface_hub import login\nimport torch\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    BitsAndBytesConfig,\n    TrainingArguments\n)\nfrom datasets import Dataset as HFDataset\nfrom peft import AutoPeftModelForCausalLM\nimport whisper\nfrom IPython.display import Audio","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:13.507795Z","iopub.status.busy":"2024-12-30T16:59:13.507511Z","iopub.status.idle":"2024-12-30T16:59:49.667726Z","shell.execute_reply":"2024-12-30T16:59:49.666822Z","shell.execute_reply.started":"2024-12-30T16:59:13.507760Z"},"id":"q_JimYqjjY4S","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Import Libraries for audio part","metadata":{"id":"E2DDMWKGSsQ5"}},{"cell_type":"code","source":"from IPython.display import HTML, Audio\nfrom google.colab.output import eval_js\nfrom base64 import b64decode\nfrom scipy.io.wavfile import read as wav_read\nimport io\nimport ffmpeg\nimport scipy","metadata":{"id":"lkjSoQT4SsQ6"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Investigate Dataset","metadata":{"id":"XKL46PcIc21t"}},{"cell_type":"code","source":"ds = load_dataset(\"medalpaca/medical_meadow_medical_flashcards\")\nds = ds['train']\nds","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:49.669293Z","iopub.status.busy":"2024-12-30T16:59:49.668679Z","iopub.status.idle":"2024-12-30T16:59:52.220997Z","shell.execute_reply":"2024-12-30T16:59:52.220340Z","shell.execute_reply.started":"2024-12-30T16:59:49.669269Z"},"id":"YltBm7i4b0IM","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(ds.features, \"\\n\")\nprint(\"Instruction:\")\nprint(f\"length: {len(ds['instruction'])}\")\nprint(f\"example: {ds['instruction'][0]} \\n\")\n\nprint(f\"Input:\")\nprint(f\"length: {len(ds['input'])}\")\nprint(f\"example: {ds['input'][0]} \\n\")\n\nprint(f\"Output:\")\nprint(f\"length: {len(ds['output'])}\")\nprint(f\"example: {ds['output'][0]} \\n\")","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.223297Z","iopub.status.busy":"2024-12-30T16:59:52.223085Z","iopub.status.idle":"2024-12-30T16:59:52.425188Z","shell.execute_reply":"2024-12-30T16:59:52.424496Z","shell.execute_reply.started":"2024-12-30T16:59:52.223279Z"},"id":"n89RynbpcHQB","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Some plots about the dataset","metadata":{"id":"a9SXu1UFoE4x"}},{"cell_type":"code","source":"instructions = ds['instruction']\ninput_phrases = ds['input']\noutput_phrases = ds['output']","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.426773Z","iopub.status.busy":"2024-12-30T16:59:52.426511Z","iopub.status.idle":"2024-12-30T16:59:52.525435Z","shell.execute_reply":"2024-12-30T16:59:52.524558Z","shell.execute_reply.started":"2024-12-30T16:59:52.426751Z"},"trusted":true,"id":"nLEtHKtISsQ7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count the frequency of each unique instruction\ninstruction_counts = {instruction: instructions.count(instruction) for instruction in set(instructions)}\n\n# Sort the instructions by frequency\nsorted_instructions = sorted(instruction_counts.items(), key=lambda x: x[1], reverse=True)\n\n# Separate the instructions and their counts for plotting\nsorted_instruction_names = [item[0] for item in sorted_instructions]\nsorted_instruction_counts = [item[1] for item in sorted_instructions]\n\n# Plotting the frequency of instructions\nplt.figure(figsize=(10, 5))\n\nbars = plt.barh(sorted_instruction_names, sorted_instruction_counts, color='skyblue', edgecolor='black', linewidth=1.2)\nplt.title('Instruction Frequency Distribution')\nplt.xlabel('Frequency')\nplt.ylabel('Instruction')\n\n# Show the plot\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.526665Z","iopub.status.busy":"2024-12-30T16:59:52.526382Z","iopub.status.idle":"2024-12-30T16:59:52.538736Z","shell.execute_reply":"2024-12-30T16:59:52.537936Z","shell.execute_reply.started":"2024-12-30T16:59:52.526643Z"},"id":"4TAMV5DdnRg7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate the length of each phrase\ninput_lengths = [len(phrase) for phrase in input_phrases]\noutput_lengths = [len(phrase) for phrase in output_phrases]\n\n# Define the bins for the length ranges\nmax_input = max(input_lengths)\nmax_output = max(output_lengths)\n\ninput_bins = [i * max_input / 10 for i in range(1, 11)]\noutput_bins = [i * max_output / 10 for i in range(1, 11)]\nbin_labels_input = [f'{int(input_bins[i-1])}-{int(input_bins[i])}' for i in range(1, 10)]\nbin_labels_output = [f'{int(output_bins[i-1])}-{int(output_bins[i])}' for i in range(1, 10)]\n\n# Bin the lengths into the categories\ninput_binned = np.digitize(input_lengths, input_bins)  # Categorize based on input lengths\noutput_binned = np.digitize(output_lengths, output_bins)  # Categorize based on output lengths\n\n# Count how many phrases fall into each bin\ninput_bin_counts = [sum(input_binned == i) for i in range(1, len(input_bins))]\noutput_bin_counts = [sum(output_binned == i) for i in range(1, len(output_bins))]\n\n# Plotting the bar charts\nplt.figure(figsize=(20, 10))\n\n# Plotting the input phrase lengths\nplt.subplot(1, 2, 1)\nplt.bar(bin_labels_input, input_bin_counts, color='skyblue', edgecolor='black')\nplt.title('Input Phrases Length Distribution')\nplt.xlabel('Length Range')\nplt.ylabel('Number of Phrases')\n\n# Plotting the output phrase lengths\nplt.subplot(1, 2, 2)\nplt.bar(bin_labels_output, output_bin_counts, color='skyblue', edgecolor='black')\nplt.title('Output Phrases Length Distribution')\nplt.xlabel('Length Range')\nplt.ylabel('Number of Phrases')\n\n# Show the plots\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.539857Z","iopub.status.busy":"2024-12-30T16:59:52.539641Z","iopub.status.idle":"2024-12-30T16:59:52.554118Z","shell.execute_reply":"2024-12-30T16:59:52.553309Z","shell.execute_reply.started":"2024-12-30T16:59:52.539829Z"},"id":"d9lEMELsiqIx","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Calculate the length of each phrase\ninput_lengths = [len(phrase) for phrase in input_phrases]\noutput_lengths = [len(phrase) for phrase in output_phrases]\n\n# Define the bins for the length ranges\nmax_input = max(input_lengths)\nmax_output = max(output_lengths)\n\ninput_bins = [i * max_input / 10 for i in range(1, 11)]\noutput_bins = [i * max_output / 10 for i in range(1, 11)]\nbin_labels_input = [f'{int(input_bins[i-1])}-{int(input_bins[i])}' for i in range(1, 10)]\nbin_labels_output = [f'{int(output_bins[i-1])}-{int(output_bins[i])}' for i in range(1, 10)]\n\n# Bin the lengths into the categories\ninput_binned = np.digitize(input_lengths, input_bins)  # Categorize based on input lengths\noutput_binned = np.digitize(output_lengths, output_bins)  # Categorize based on output lengths\n\n# Count how many phrases fall into each bin\ninput_bin_counts = [sum(input_binned == i) for i in range(1, len(input_bins))]\noutput_bin_counts = [sum(output_binned == i) for i in range(1, len(output_bins))]\n\n# Plotting the bar charts with improved styling\nplt.figure(figsize=(20, 10))\n\n# Plotting the input phrase lengths\nplt.subplot(1, 2, 1)\nbars_input = plt.bar(bin_labels_input, input_bin_counts, color='#FF6347', edgecolor='black', linewidth=1.2)\nplt.title('Input Phrases Length Distribution', fontsize=16, weight='bold', color='#2F4F4F')\nplt.xlabel('Length Range', fontsize=14, color='#2F4F4F')\nplt.ylabel('Number of Phrases', fontsize=14, color='#2F4F4F')\nplt.xticks(rotation=45, ha='right')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\n\n# Add data labels on bars for input\nfor bar in bars_input:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width() / 2, yval + 1, int(yval), ha='center', fontsize=12, color='black')\n\n# Plotting the output phrase lengths\nplt.subplot(1, 2, 2)\nbars_output = plt.bar(bin_labels_output, output_bin_counts, color='#4682B4', edgecolor='black', linewidth=1.2)\nplt.title('Output Phrases Length Distribution', fontsize=16, weight='bold', color='#2F4F4F')\nplt.xlabel('Length Range', fontsize=14, color='#2F4F4F')\nplt.ylabel('Number of Phrases', fontsize=14, color='#2F4F4F')\nplt.xticks(rotation=45, ha='right')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\n\n# Add data labels on bars for output\nfor bar in bars_output:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width() / 2, yval + 1, int(yval), ha='center', fontsize=12, color='black')\n\n# Show the plots\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Extra plot","metadata":{}},{"cell_type":"code","source":"# Word cloud\nfrom wordcloud import WordCloud\n\ninput = ' '.join(input_phrases)\noutput = ' '.join(output_phrases)\n\nwordcloud1 = WordCloud(width=800, height=400, background_color='white').generate(input)\nwordcloud2 = WordCloud(width=800, height=400, background_color='white').generate(output)\n\n# Plotting the bar charts\nplt.figure(figsize=(20, 10))\n\n# Plotting the input phrase lengths\nplt.subplot(1, 2, 1)\nplt.imshow(wordcloud1, interpolation='bilinear')\nplt.axis('off')\nplt.title('Question Word Cloud')\n\n# Plotting the output phrase lengths\nplt.subplot(1, 2, 2)\nplt.imshow(wordcloud2, interpolation='bilinear')\nplt.axis('off')\nplt.title('Answer Word Cloud')\n\n# Show the plots\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Converti input_phrases in una Series\ninput_series = pd.Series(input_phrases)\n\n# Applica il preprocessing\ninput_series = input_series.apply(preprocess)\n\n# Conta le parole\nword_counts = Counter([word for tokens in input_series for word in tokens])\nmost_common = word_counts.most_common(20)\n\n# Prepara i dati per il grafico\nwords1, counts1 = zip(*most_common)\n\n# Converti output_phrases in una Series\noutput_series = pd.Series(output_phrases)\n\n# Applica il preprocessing\noutput_series = output_series.apply(preprocess)\n\n# Conta le parole\nword_counts = Counter([word for tokens in output_series for word in tokens])\nmost_common = word_counts.most_common(20)\n\n# Prepara i dati per il grafico\nwords2, counts2 = zip(*most_common)\n\n# Plotting the bar charts side by side\nplt.figure(figsize=(20, 10))\n\n# First subplot (Input Phrases)\nplt.subplot(1, 2, 1)\nsns.barplot(x=list(counts1), y=list(words1), palette='viridis')\nplt.title('Top 20 Most Frequent Words in Input Phrases')\nplt.xlabel('Frequency')\nplt.ylabel('Words')\n\n# Second subplot (Output Phrases)\nplt.subplot(1, 2, 2)\nsns.barplot(x=list(counts2), y=list(words2), palette='viridis')\nplt.title('Top 20 Most Frequent Words in Output Phrases')\nplt.xlabel('Frequency')\nplt.ylabel('Words')\n\n# Adjust layout and show the plots\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tokenize","metadata":{"id":"7zqoFYTT2lyy"}},{"cell_type":"code","source":"tokenized_sentences = [re.sub('\\W', ' ', sentence).lower().split() for sentence in input_phrases]\n# remove sentences that are only 1 word long\ntokenized_sentences = [sentence for sentence in tokenized_sentences if len(sentence) > 1]\n\nfor sentence in tokenized_sentences[:5]:\n    print(sentence)","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.555314Z","iopub.status.busy":"2024-12-30T16:59:52.555019Z","iopub.status.idle":"2024-12-30T16:59:52.819665Z","shell.execute_reply":"2024-12-30T16:59:52.818721Z","shell.execute_reply.started":"2024-12-30T16:59:52.555284Z"},"id":"wRH-mf5T2lyy","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# merge in & out togheter\n# merged_list = [f\"{a} {b}\" for a, b in zip(input_phrases, output_phrases)]\n\n# remove newline characters\n# docs = [re.sub('\\n', ' ', doc) for doc in merged_list]\n# split sentences\n#sentences = [re.split('[?!.]\\s', doc) for doc in docs]\n#sentences[:3]","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.821010Z","iopub.status.busy":"2024-12-30T16:59:52.820700Z","iopub.status.idle":"2024-12-30T16:59:52.824373Z","shell.execute_reply":"2024-12-30T16:59:52.823663Z","shell.execute_reply.started":"2024-12-30T16:59:52.820979Z"},"id":"yZ8ZCHgj2lyy","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from pandas.core.common import flatten\n\n# sentences = list(flatten(sentences))\n# sentences[:20]","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.825374Z","iopub.status.busy":"2024-12-30T16:59:52.825148Z","iopub.status.idle":"2024-12-30T16:59:52.839850Z","shell.execute_reply":"2024-12-30T16:59:52.839128Z","shell.execute_reply.started":"2024-12-30T16:59:52.825353Z"},"id":"yedEUf_32lyy","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Word2Vec","metadata":{"id":"f4wIndWS2lyy"}},{"cell_type":"code","source":"model = Word2Vec(tokenized_sentences, vector_size=30, min_count=5, window=10)","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.841003Z","iopub.status.busy":"2024-12-30T16:59:52.840758Z","iopub.status.idle":"2024-12-30T16:59:52.851850Z","shell.execute_reply":"2024-12-30T16:59:52.851270Z","shell.execute_reply.started":"2024-12-30T16:59:52.840983Z"},"id":"e05BkgN-2lyz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample = random.sample(list(model.wv.key_to_index), 500)\nword_vectors = model.wv[sample]","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.852897Z","iopub.status.busy":"2024-12-30T16:59:52.852659Z","iopub.status.idle":"2024-12-30T16:59:52.864549Z","shell.execute_reply":"2024-12-30T16:59:52.863727Z","shell.execute_reply.started":"2024-12-30T16:59:52.852865Z"},"id":"blQAYdGr2lyz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3D plot with words","metadata":{"id":"CskZCC7a2lyz"}},{"cell_type":"code","source":"tsne = TSNE(n_components=3, n_iter=2000)\ntsne_embedding = tsne.fit_transform(word_vectors)\n\nx, y, z = np.transpose(tsne_embedding)\n\nfig = px.scatter_3d(x=x[:200],y=y[:200],z=z[:200],text=sample[:200])\nfig.update_traces(marker=dict(size=3,line=dict(width=2)),textfont_size=10)\nfig.show()","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.867538Z","iopub.status.busy":"2024-12-30T16:59:52.867355Z","iopub.status.idle":"2024-12-30T16:59:52.876777Z","shell.execute_reply":"2024-12-30T16:59:52.876193Z","shell.execute_reply.started":"2024-12-30T16:59:52.867521Z"},"id":"_0EGqbEA2lyz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"first_question = ['man', 'woman']\n#question = ['rem', 'sleep', 'hallucinations', 'paralysis']\n\nword_vectors = model.wv[first_question+sample]\n\ntsne = TSNE(n_components=3)\ntsne_embedding = tsne.fit_transform(word_vectors)\n\nx, y, z = np.transpose(tsne_embedding)","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.878683Z","iopub.status.busy":"2024-12-30T16:59:52.878417Z","iopub.status.idle":"2024-12-30T16:59:52.889273Z","shell.execute_reply":"2024-12-30T16:59:52.888545Z","shell.execute_reply.started":"2024-12-30T16:59:52.878662Z"},"id":"ruxbKZBt2lyz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"r = (-20,20)\nfig = px.scatter_3d(x=x, y=y, z=z, range_x=r, range_y=r, range_z=r, text=first_question + [None] * 500)\nfig.update_traces(marker=dict(size=3,line=dict(width=2)),textfont_size=10)\nfig.show()","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.890313Z","iopub.status.busy":"2024-12-30T16:59:52.890087Z","iopub.status.idle":"2024-12-30T16:59:52.902336Z","shell.execute_reply":"2024-12-30T16:59:52.901559Z","shell.execute_reply.started":"2024-12-30T16:59:52.890293Z"},"id":"Cem4IiRb2lyz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.wv.most_similar('menopause')","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.903428Z","iopub.status.busy":"2024-12-30T16:59:52.903158Z","iopub.status.idle":"2024-12-30T16:59:52.915056Z","shell.execute_reply":"2024-12-30T16:59:52.914368Z","shell.execute_reply.started":"2024-12-30T16:59:52.903400Z"},"id":"E795I6ej2lyz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vec = model.wv.get_vector('headache') + (model.wv.get_vector('fever') - model.wv.get_vector('drug'))\nmodel.wv.similar_by_vector(vec)","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.916083Z","iopub.status.busy":"2024-12-30T16:59:52.915796Z","iopub.status.idle":"2024-12-30T16:59:52.927087Z","shell.execute_reply":"2024-12-30T16:59:52.926279Z","shell.execute_reply.started":"2024-12-30T16:59:52.916062Z"},"id":"8RkQLdpv2lyz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train and evaluate models","metadata":{"id":"-BMh1vbuc5qp"}},{"cell_type":"markdown","source":"#### Create dataset","metadata":{"id":"VFt5KLR-8w3p"}},{"cell_type":"code","source":"# class MedDataset(Dataset):\n#   def __init__(self, instruction, input, output):\n#     self.instruction = instruction\n#     self.input = input\n#     self.output = output\n\n#   def __len__(self):\n#     return len(self.instruction)\n\n#   def __getitem__(self, idx):\n#     sentence = \"<s>[INST] \"+self.instruction[idx]+\". \"+self.input[idx]+\" [/INST] \"+self.output[idx]+\" </s>\"\n#     return sentence","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.928108Z","iopub.status.busy":"2024-12-30T16:59:52.927875Z","iopub.status.idle":"2024-12-30T16:59:52.938991Z","shell.execute_reply":"2024-12-30T16:59:52.938276Z","shell.execute_reply.started":"2024-12-30T16:59:52.928088Z"},"id":"ND0M0R633VbB","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MedDataset(Dataset):\n    def __init__(self, dataset, tokenizer):\n        self.dataset = dataset\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        example = self.dataset[idx]\n        messages = [\n            {\"role\": \"system\", \"content\": example['instruction']},\n            {\"role\": \"user\", \"content\": example['input']},\n            {\"role\": \"assistant\", \"content\": example['output']}\n        ]\n\n        prompt = self.tokenizer.apply_chat_template(\n            messages,\n            tokenize=False,\n            add_generation_prompt=True\n        )\n\n        tokens = self.tokenizer(\n            prompt,\n            padding=\"max_length\",\n            truncation=True,\n            max_length=128,\n            return_tensors=\"pt\"\n        )\n\n        tokens['labels'] = tokens['input_ids'].clone()\n        tokens['labels'][tokens['input_ids'] == self.tokenizer.pad_token_id] = -100\n\n        return {\n            \"input_ids\": tokens['input_ids'].squeeze(),\n            \"attention_mask\": tokens['attention_mask'].squeeze(),\n            \"labels\": tokens['labels'].squeeze()\n        }","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.940011Z","iopub.status.busy":"2024-12-30T16:59:52.939776Z","iopub.status.idle":"2024-12-30T16:59:52.951321Z","shell.execute_reply":"2024-12-30T16:59:52.950710Z","shell.execute_reply.started":"2024-12-30T16:59:52.939981Z"},"trusted":true,"id":"LacKbkPHSsQ-"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"login(token=\"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\")\n\nbase_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n\ntokenizer = AutoTokenizer.from_pretrained(base_model)\ntokenizer.pad_token = tokenizer.eos_token\n\n# tokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:52.952410Z","iopub.status.busy":"2024-12-30T16:59:52.952160Z","iopub.status.idle":"2024-12-30T16:59:55.064154Z","shell.execute_reply":"2024-12-30T16:59:55.063424Z","shell.execute_reply.started":"2024-12-30T16:59:52.952378Z"},"trusted":true,"id":"AelKMq1xSsQ-"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_dataset = MedDataset(ds, tokenizer)","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:55.065221Z","iopub.status.busy":"2024-12-30T16:59:55.064916Z","iopub.status.idle":"2024-12-30T16:59:55.128355Z","shell.execute_reply":"2024-12-30T16:59:55.127665Z","shell.execute_reply.started":"2024-12-30T16:59:55.065191Z"},"id":"C6gCSyFM7IsG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset, val_dataset, test_dataset = random_split(tokenized_dataset, [0.8, 0.1, 0.1])\nprint(f\"Train dataset dimension: {len(train_dataset)}\")\nprint(f\"Validation dataset dimension: {len(val_dataset)}\")\nprint(f\"Test dataset dimension: {len(test_dataset)}\")","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:55.129451Z","iopub.status.busy":"2024-12-30T16:59:55.129104Z","iopub.status.idle":"2024-12-30T16:59:55.142171Z","shell.execute_reply":"2024-12-30T16:59:55.141484Z","shell.execute_reply.started":"2024-12-30T16:59:55.129421Z"},"id":"RRneCjBj9Lag","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def convert_to_hf_dataset(med_dataset):\n#     # Create lists to store all formatted text\n#     formatted_texts = []\n\n#     # Iterate through all items in the original dataset\n#     for idx in range(len(med_dataset.instruction)):\n#         # Get the formatted text directly using the dataset's __getitem__\n#         formatted_text = med_dataset[idx]\n#         formatted_texts.append(formatted_text)\n\n#     # Create a dictionary with the required format\n#     dataset_dict = {\n#         'text': formatted_texts\n#     }\n\n#     # Convert to HuggingFace Dataset\n#     hf_dataset = HFDataset.from_dict(dataset_dict)\n\n#     return hf_dataset\n\n# hf_dataset = convert_to_hf_dataset(garnachoDataset)","metadata":{"id":"gzL6yXsGSsQ_"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\n\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_representation=\"nested\"\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    quantization_config=quant_config,\n    device_map={\"\": 0},\n    torch_dtype=torch.float32,\n    trust_remote_code=True\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.execute_input":"2024-12-30T16:59:55.142987Z","iopub.status.busy":"2024-12-30T16:59:55.142794Z","iopub.status.idle":"2024-12-30T17:00:59.593527Z","shell.execute_reply":"2024-12-30T17:00:59.592693Z","shell.execute_reply.started":"2024-12-30T16:59:55.142969Z"},"id":"gR4BtF8AHD0I","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"peft_params = LoraConfig(\n    lora_alpha=32,\n    lora_dropout=0.1,\n    r=16,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.execute_input":"2024-12-30T17:00:59.601461Z","iopub.status.busy":"2024-12-30T17:00:59.601147Z","iopub.status.idle":"2024-12-30T17:00:59.614772Z","shell.execute_reply":"2024-12-30T17:00:59.614099Z","shell.execute_reply.started":"2024-12-30T17:00:59.601433Z"},"id":"ew98HuwaKW1P","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.train()\ntraining_params = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=4,\n    optim=\"paged_adamw_32bit\",\n    eval_strategy=\"steps\",\n    logging_steps=90,\n    eval_steps = 90,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n    report_to=\"tensorboard\",\n    gradient_checkpointing=True\n)","metadata":{"execution":{"iopub.execute_input":"2024-12-30T17:00:59.615833Z","iopub.status.busy":"2024-12-30T17:00:59.615586Z","iopub.status.idle":"2024-12-30T17:00:59.653074Z","shell.execute_reply":"2024-12-30T17:00:59.652283Z","shell.execute_reply.started":"2024-12-30T17:00:59.615814Z"},"id":"n8dBHX-j-M1J","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    peft_config=peft_params,\n    max_seq_length=256,\n    tokenizer=tokenizer,\n    args=training_params,\n    packing=False,\n)\n\n# Train the model\ntrainer.train()\n\n# Save the model and tokenizer\ntrainer.save_model(\"./fine-tuned-model\")\ntokenizer.save_pretrained(\"./fine-tuned-model\")","metadata":{"execution":{"iopub.execute_input":"2024-12-30T17:00:59.654307Z","iopub.status.busy":"2024-12-30T17:00:59.654001Z","iopub.status.idle":"2024-12-30T18:27:02.782730Z","shell.execute_reply":"2024-12-30T18:27:02.781673Z","shell.execute_reply.started":"2024-12-30T17:00:59.654278Z"},"trusted":true,"id":"ARnpWrEFSsQ_"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.model.save_pretrained(\"model-chatbot-medical-mew\")\ntrainer.tokenizer.save_pretrained(\"model-chatbot-medical-mew\")","metadata":{"execution":{"iopub.execute_input":"2024-12-30T18:40:06.102654Z","iopub.status.busy":"2024-12-30T18:40:06.102303Z","iopub.status.idle":"2024-12-30T18:40:06.608165Z","shell.execute_reply":"2024-12-30T18:40:06.607233Z","shell.execute_reply.started":"2024-12-30T18:40:06.102626Z"},"id":"awbFBy8v5rDM","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test Trained Model","metadata":{"id":"MmC39wTYSsQ_"}},{"cell_type":"markdown","source":"### Load pre-trained model\n\n> Aggiungi citazione\n\n","metadata":{"id":"UwQNV8XLYoLX"}},{"cell_type":"code","source":"trained_model = \"/kaggle/working/model-chatbot-medical-mew\"\nquestion = \"What does low Mobility suggest?\"\n\nmodel = AutoPeftModelForCausalLM.from_pretrained(\n    trained_model, # change with folder where u have the files\n    quantization_config=quant_config,\n    device_map={\"\": 0},\n    torch_dtype=torch.float32,\n    trust_remote_code=True\n)\ntokenizer = AutoTokenizer.from_pretrained(trained_model)","metadata":{"id":"A-XhCQC1YhLP"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"messages = [{\"role\": \"system\", \"content\": instructions[0]},\n    {\"role\": \"user\", \"content\": question}]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n\nmodel_inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\noutputs = model.generate(**model_inputs, max_new_tokens=128)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(f\"Question: {question}\")\nprint(text.split(\"assistant\")[1])","metadata":{"execution":{"iopub.execute_input":"2024-12-30T18:43:01.327614Z","iopub.status.busy":"2024-12-30T18:43:01.327258Z","iopub.status.idle":"2024-12-30T18:43:10.136652Z","shell.execute_reply":"2024-12-30T18:43:10.135919Z","shell.execute_reply.started":"2024-12-30T18:43:01.327584Z"},"trusted":true,"id":"NL-rYUPJSsRD"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Add voice interactivity","metadata":{"id":"kPKlNEM_sFu0"}},{"cell_type":"markdown","source":"### Record Audio","metadata":{"id":"3QSzEjW2MZrc"}},{"cell_type":"code","source":"\"\"\"\nReferences:\nhttps://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\nhttps://stackoverflow.com/a/18650249\nhttps://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\nhttps://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\nhttps://stackoverflow.com/a/49019356\n\"\"\"\n\nAUDIO_HTML = \"\"\"\n<script>\nvar my_div = document.createElement(\"DIV\");\nvar my_p = document.createElement(\"P\");\nvar my_btn = document.createElement(\"BUTTON\");\nvar t = document.createTextNode(\"Press to start recording\");\n\nmy_btn.appendChild(t);\n//my_p.appendChild(my_btn);\nmy_div.appendChild(my_btn);\ndocument.body.appendChild(my_div);\n\nvar base64data = 0;\nvar reader;\nvar recorder, gumStream;\nvar recordButton = my_btn;\n\nvar handleSuccess = function(stream) {\n  gumStream = stream;\n  var options = {\n    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n    mimeType : 'audio/webm;codecs=opus'\n    //mimeType : 'audio/webm;codecs=pcm'\n  };\n  //recorder = new MediaRecorder(stream, options);\n  recorder = new MediaRecorder(stream);\n  recorder.ondataavailable = function(e) {\n    var url = URL.createObjectURL(e.data);\n    var preview = document.createElement('audio');\n    preview.controls = true;\n    preview.src = url;\n    document.body.appendChild(preview);\n\n    reader = new FileReader();\n    reader.readAsDataURL(e.data);\n    reader.onloadend = function() {\n      base64data = reader.result;\n      //console.log(\"Inside FileReader:\" + base64data);\n    }\n  };\n  recorder.start();\n  };\n\nrecordButton.innerText = \"Recording... press to stop\";\n\nnavigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n\n\nfunction toggleRecording() {\n  if (recorder && recorder.state == \"recording\") {\n      recorder.stop();\n      gumStream.getAudioTracks()[0].stop();\n      recordButton.innerText = \"Saving the recording... pls wait!\"\n  }\n}\n\n// https://stackoverflow.com/a/951057\nfunction sleep(ms) {\n  return new Promise(resolve => setTimeout(resolve, ms));\n}\n\nvar data = new Promise(resolve=>{\n//recordButton.addEventListener(\"click\", toggleRecording);\nrecordButton.onclick = ()=>{\ntoggleRecording()\n\nsleep(2000).then(() => {\n  // wait 2000ms for the data to be available...\n  // ideally this should use something like await...\n  //console.log(\"Inside data:\" + base64data)\n  resolve(base64data.toString())\n\n});\n\n}\n});\n\n</script>\n\"\"\"\n\ndef get_audio():\n  display(HTML(AUDIO_HTML))\n  data = eval_js(\"data\")\n  binary = b64decode(data.split(',')[1])\n\n  process = (ffmpeg\n    .input('pipe:0')\n    .output('pipe:1', format='wav')\n    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n  )\n  output, err = process.communicate(input=binary)\n\n  riff_chunk_size = len(output) - 8\n  # Break up the chunk size into four bytes, held in b.\n  q = riff_chunk_size\n  b = []\n  for i in range(4):\n      q, r = divmod(q, 256)\n      b.append(r)\n\n  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n  riff = output[:4] + bytes(b) + output[8:]\n\n  sr, audio = wav_read(io.BytesIO(riff))\n\n  return audio, sr","metadata":{"execution":{"iopub.status.busy":"2024-12-30T18:27:02.852003Z","iopub.status.idle":"2024-12-30T18:27:02.852305Z","shell.execute_reply":"2024-12-30T18:27:02.852202Z"},"id":"7uLKcUMQMeaL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"audio, sr = get_audio()","metadata":{"execution":{"iopub.status.busy":"2024-12-30T18:27:02.852822Z","iopub.status.idle":"2024-12-30T18:27:02.853094Z","shell.execute_reply":"2024-12-30T18:27:02.852969Z"},"id":"oo1ink-uMiYo","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scipy.io.wavfile.write('./recording.wav', sr, audio)","metadata":{"execution":{"iopub.status.busy":"2024-12-30T18:27:02.853655Z","iopub.status.idle":"2024-12-30T18:27:02.853877Z","shell.execute_reply":"2024-12-30T18:27:02.853788Z"},"id":"DaV9sVvZMlCL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Speech to Text","metadata":{"id":"_1k0fMEMNtl2"}},{"cell_type":"code","source":"whis = whisper.load_model(\"base\")\n\n# load audio and pad/trim it to fit 30 seconds\naudio = whisper.load_audio(\"./recording.wav\")\naudio = whisper.pad_or_trim(audio)\n\n# load audio and pad/trim it to fit 30 seconds\nfig = plt.figure(figsize=(16,4))\nplt.plot(audio, linewidth=0.4)\nplt.ylabel('Amplitude')\nplt.xlabel('Samples')\nplt.show()\n\n# make log-Mel spectrogram and move to the same device as the model\nmel = whisper.log_mel_spectrogram(audio).to(whis.device)\n\n# Visualize spectrogram\nfig = plt.figure(figsize=(10,4))\nplt.pcolormesh(mel.cpu().numpy())\nplt.colorbar(label='Power [dB]')\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [10ms]')\nplt.show()\n\n# Use the mel spectrogram to detect the language\n_, probs = whis.detect_language(mel)\nlang = max(probs, key=probs.get)\n\n# Print result\nprint(f\"Detected language: {lang}, confidence: {probs[lang]}\")\n\n# decode the audio\noptions = whisper.DecodingOptions(fp16 = False)\nresult = whisper.decode(whis, mel, options)\n\n# print the recognized text\nprint(result.text)","metadata":{"execution":{"iopub.status.busy":"2024-12-30T18:27:02.854542Z","iopub.status.idle":"2024-12-30T18:27:02.854872Z","shell.execute_reply":"2024-12-30T18:27:02.854712Z"},"id":"sPQmD992Lpjh","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dump result text into model\ninputs = tokenizer(result.text, return_tensors=\"pt\")\ninputs = {k: v.to(model.device) for k, v in inputs.items()}\noutput = model.generate(**inputs)","metadata":{"execution":{"iopub.status.busy":"2024-12-30T18:27:02.855837Z","iopub.status.idle":"2024-12-30T18:27:02.856217Z","shell.execute_reply":"2024-12-30T18:27:02.856058Z"},"id":"La6g7PIIN3yo","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Text to Speech","metadata":{"id":"LZLo43qaNyqn"}},{"cell_type":"code","source":"tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\ntacotron2 = tacotron2.to('cuda')\ntacotron2.eval()","metadata":{"execution":{"iopub.status.busy":"2024-12-30T18:27:02.857137Z","iopub.status.idle":"2024-12-30T18:27:02.857562Z","shell.execute_reply":"2024-12-30T18:27:02.857350Z"},"id":"DVEewwceOF-Y","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp16')\nwaveglow = waveglow.remove_weightnorm(waveglow)\nwaveglow = waveglow.to('cuda')\nwaveglow.eval()","metadata":{"execution":{"iopub.status.busy":"2024-12-30T18:27:02.858937Z","iopub.status.idle":"2024-12-30T18:27:02.859342Z","shell.execute_reply":"2024-12-30T18:27:02.859184Z"},"id":"tcKqPWGXOJz9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add model response\nprint(tokenizer.decode(output[0]))\ntext = tokenizer.decode(output[0])","metadata":{"execution":{"iopub.status.busy":"2024-12-30T18:27:02.860028Z","iopub.status.idle":"2024-12-30T18:27:02.860393Z","shell.execute_reply":"2024-12-30T18:27:02.860239Z"},"id":"DlHbL8_YOMON","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\nsequences, lengths = utils.prepare_input_sequence([text])\nsequences","metadata":{"execution":{"iopub.status.busy":"2024-12-30T18:27:02.861323Z","iopub.status.idle":"2024-12-30T18:27:02.861724Z","shell.execute_reply":"2024-12-30T18:27:02.861556Z"},"id":"SYGrvo4YOOBX","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with torch.no_grad():\n    mel, _, _ = tacotron2.infer(sequences, lengths)\n\n%matplotlib inline\n\nfig = plt.figure(figsize=(10,4))\nplt.pcolormesh(mel[0].cpu().numpy())\nplt.colorbar(label='Power [dB]')\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [10ms]')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-30T18:27:02.862526Z","iopub.status.idle":"2024-12-30T18:27:02.862883Z","shell.execute_reply":"2024-12-30T18:27:02.862729Z"},"id":"oOyIqRq9OQJP","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with torch.no_grad():\n    audio = waveglow.infer(mel)\naudio_numpy = audio[0].data.cpu().numpy()\nrate = 22050\n\nfig = plt.figure(figsize=(16,4))\nplt.plot(audio_numpy, linewidth=0.4)\nplt.ylabel('Amplitude')\nplt.xlabel('Samples')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-12-30T18:27:02.863553Z","iopub.status.idle":"2024-12-30T18:27:02.863999Z","shell.execute_reply":"2024-12-30T18:27:02.863754Z"},"id":"t-dE1l-dOVwn","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Audio(audio_numpy, rate=rate)","metadata":{"execution":{"iopub.status.busy":"2024-12-30T18:27:02.864777Z","iopub.status.idle":"2024-12-30T18:27:02.865156Z","shell.execute_reply":"2024-12-30T18:27:02.864977Z"},"id":"PNwE-1SuObFF","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Potential extensions","metadata":{"id":"s22bSn7_sFu6"}},{"cell_type":"code","source":"","metadata":{"id":"h1mPCVNJdGSr","trusted":true},"outputs":[],"execution_count":null}]}