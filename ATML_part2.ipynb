{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sAndreotti/MedicalMeadow/blob/voice/ATML_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29nxqgohSsQ3"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:58:25.513090Z",
          "iopub.status.busy": "2024-12-30T16:58:25.512794Z",
          "iopub.status.idle": "2024-12-30T16:59:13.506495Z",
          "shell.execute_reply": "2024-12-30T16:59:13.505543Z",
          "shell.execute_reply.started": "2024-12-30T16:58:25.513052Z"
        },
        "id": "SAho3HGib9-U",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install datasets accelerate peft bitsandbytes transformers trl==0.12.0 plotly huggingface_hub\n",
        "!pip install --upgrade smart_open\n",
        "!pip install --upgrade gensim\n",
        "!pip install ffmpeg-python\n",
        "!pip install -U openai-whisper\n",
        "\n",
        "# Modificato\n",
        "!pip install scipy librosa unidecode inflect\n",
        "!pip install pydub noisereduce\n",
        "\n",
        "# For text to speech\n",
        "!pip install TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:13.507795Z",
          "iopub.status.busy": "2024-12-30T16:59:13.507511Z",
          "iopub.status.idle": "2024-12-30T16:59:49.667726Z",
          "shell.execute_reply": "2024-12-30T16:59:49.666822Z",
          "shell.execute_reply.started": "2024-12-30T16:59:13.507760Z"
        },
        "id": "q_JimYqjjY4S",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from trl import SFTTrainer\n",
        "import re\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import plotly.express as px\n",
        "import random\n",
        "from sklearn.manifold import TSNE\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "from peft import prepare_model_for_kbit_training, LoraConfig\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments\n",
        ")\n",
        "from datasets import Dataset as HFDataset\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "import whisper\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2DDMWKGSsQ5"
      },
      "source": [
        "Import Libraries for audio part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkjSoQT4SsQ6"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKL46PcIc21t"
      },
      "source": [
        "## Investigate Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:49.669293Z",
          "iopub.status.busy": "2024-12-30T16:59:49.668679Z",
          "iopub.status.idle": "2024-12-30T16:59:52.220997Z",
          "shell.execute_reply": "2024-12-30T16:59:52.220340Z",
          "shell.execute_reply.started": "2024-12-30T16:59:49.669269Z"
        },
        "id": "YltBm7i4b0IM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "ds = load_dataset(\"medalpaca/medical_meadow_medical_flashcards\")\n",
        "ds = ds['train']\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.223297Z",
          "iopub.status.busy": "2024-12-30T16:59:52.223085Z",
          "iopub.status.idle": "2024-12-30T16:59:52.425188Z",
          "shell.execute_reply": "2024-12-30T16:59:52.424496Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.223279Z"
        },
        "id": "n89RynbpcHQB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(ds.features, \"\\n\")\n",
        "print(\"Instruction:\")\n",
        "print(f\"length: {len(ds['instruction'])}\")\n",
        "print(f\"example: {ds['instruction'][0]} \\n\")\n",
        "\n",
        "print(f\"Input:\")\n",
        "print(f\"length: {len(ds['input'])}\")\n",
        "print(f\"example: {ds['input'][0]} \\n\")\n",
        "\n",
        "print(f\"Output:\")\n",
        "print(f\"length: {len(ds['output'])}\")\n",
        "print(f\"example: {ds['output'][0]} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9SXu1UFoE4x"
      },
      "source": [
        "### Some plots about the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.426773Z",
          "iopub.status.busy": "2024-12-30T16:59:52.426511Z",
          "iopub.status.idle": "2024-12-30T16:59:52.525435Z",
          "shell.execute_reply": "2024-12-30T16:59:52.524558Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.426751Z"
        },
        "trusted": true,
        "id": "nLEtHKtISsQ7"
      },
      "outputs": [],
      "source": [
        "instructions = ds['instruction']\n",
        "input_phrases = ds['input']\n",
        "output_phrases = ds['output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.526665Z",
          "iopub.status.busy": "2024-12-30T16:59:52.526382Z",
          "iopub.status.idle": "2024-12-30T16:59:52.538736Z",
          "shell.execute_reply": "2024-12-30T16:59:52.537936Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.526643Z"
        },
        "id": "4TAMV5DdnRg7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Count the frequency of each unique instruction\n",
        "instruction_counts = {instruction: instructions.count(instruction) for instruction in set(instructions)}\n",
        "\n",
        "# Sort the instructions by frequency\n",
        "sorted_instructions = sorted(instruction_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Separate the instructions and their counts for plotting\n",
        "sorted_instruction_names = [item[0] for item in sorted_instructions]\n",
        "sorted_instruction_counts = [item[1] for item in sorted_instructions]\n",
        "\n",
        "# Plotting the frequency of instructions\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bars = plt.barh(sorted_instruction_names, sorted_instruction_counts, color='skyblue', edgecolor='black', linewidth=1.2)\n",
        "plt.title('Instruction Frequency Distribution')\n",
        "plt.xlabel('Frequency')\n",
        "plt.ylabel('Instruction')\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.539857Z",
          "iopub.status.busy": "2024-12-30T16:59:52.539641Z",
          "iopub.status.idle": "2024-12-30T16:59:52.554118Z",
          "shell.execute_reply": "2024-12-30T16:59:52.553309Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.539829Z"
        },
        "id": "d9lEMELsiqIx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Calculate the length of each phrase\n",
        "input_lengths = [len(phrase) for phrase in input_phrases]\n",
        "output_lengths = [len(phrase) for phrase in output_phrases]\n",
        "\n",
        "# Define the bins for the length ranges\n",
        "max_input = max(input_lengths)\n",
        "max_output = max(output_lengths)\n",
        "\n",
        "input_bins = [i * max_input / 10 for i in range(1, 11)]\n",
        "output_bins = [i * max_output / 10 for i in range(1, 11)]\n",
        "bin_labels_input = [f'{int(input_bins[i-1])}-{int(input_bins[i])}' for i in range(1, 10)]\n",
        "bin_labels_output = [f'{int(output_bins[i-1])}-{int(output_bins[i])}' for i in range(1, 10)]\n",
        "\n",
        "# Bin the lengths into the categories\n",
        "input_binned = np.digitize(input_lengths, input_bins)  # Categorize based on input lengths\n",
        "output_binned = np.digitize(output_lengths, output_bins)  # Categorize based on output lengths\n",
        "\n",
        "# Count how many phrases fall into each bin\n",
        "input_bin_counts = [sum(input_binned == i) for i in range(1, len(input_bins))]\n",
        "output_bin_counts = [sum(output_binned == i) for i in range(1, len(output_bins))]\n",
        "\n",
        "# Plotting the bar charts\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "# Plotting the input phrase lengths\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(bin_labels_input, input_bin_counts, color='skyblue', edgecolor='black')\n",
        "plt.title('Input Phrases Length Distribution')\n",
        "plt.xlabel('Length Range')\n",
        "plt.ylabel('Number of Phrases')\n",
        "\n",
        "# Plotting the output phrase lengths\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(bin_labels_output, output_bin_counts, color='skyblue', edgecolor='black')\n",
        "plt.title('Output Phrases Length Distribution')\n",
        "plt.xlabel('Length Range')\n",
        "plt.ylabel('Number of Phrases')\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zqoFYTT2lyy"
      },
      "source": [
        "## Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.555314Z",
          "iopub.status.busy": "2024-12-30T16:59:52.555019Z",
          "iopub.status.idle": "2024-12-30T16:59:52.819665Z",
          "shell.execute_reply": "2024-12-30T16:59:52.818721Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.555284Z"
        },
        "id": "wRH-mf5T2lyy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "tokenized_sentences = [re.sub('\\W', ' ', sentence).lower().split() for sentence in input_phrases]\n",
        "# remove sentences that are only 1 word long\n",
        "tokenized_sentences = [sentence for sentence in tokenized_sentences if len(sentence) > 1]\n",
        "\n",
        "for sentence in tokenized_sentences[:5]:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.821010Z",
          "iopub.status.busy": "2024-12-30T16:59:52.820700Z",
          "iopub.status.idle": "2024-12-30T16:59:52.824373Z",
          "shell.execute_reply": "2024-12-30T16:59:52.823663Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.820979Z"
        },
        "id": "yZ8ZCHgj2lyy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# merge in & out togheter\n",
        "# merged_list = [f\"{a} {b}\" for a, b in zip(input_phrases, output_phrases)]\n",
        "\n",
        "# remove newline characters\n",
        "# docs = [re.sub('\\n', ' ', doc) for doc in merged_list]\n",
        "# split sentences\n",
        "#sentences = [re.split('[?!.]\\s', doc) for doc in docs]\n",
        "#sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.825374Z",
          "iopub.status.busy": "2024-12-30T16:59:52.825148Z",
          "iopub.status.idle": "2024-12-30T16:59:52.839850Z",
          "shell.execute_reply": "2024-12-30T16:59:52.839128Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.825353Z"
        },
        "id": "yedEUf_32lyy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# from pandas.core.common import flatten\n",
        "\n",
        "# sentences = list(flatten(sentences))\n",
        "# sentences[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4wIndWS2lyy"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.841003Z",
          "iopub.status.busy": "2024-12-30T16:59:52.840758Z",
          "iopub.status.idle": "2024-12-30T16:59:52.851850Z",
          "shell.execute_reply": "2024-12-30T16:59:52.851270Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.840983Z"
        },
        "id": "e05BkgN-2lyz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(tokenized_sentences, vector_size=30, min_count=5, window=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.852897Z",
          "iopub.status.busy": "2024-12-30T16:59:52.852659Z",
          "iopub.status.idle": "2024-12-30T16:59:52.864549Z",
          "shell.execute_reply": "2024-12-30T16:59:52.863727Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.852865Z"
        },
        "id": "blQAYdGr2lyz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sample = random.sample(list(model.wv.key_to_index), 500)\n",
        "word_vectors = model.wv[sample]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CskZCC7a2lyz"
      },
      "source": [
        "### 3D plot with words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.867538Z",
          "iopub.status.busy": "2024-12-30T16:59:52.867355Z",
          "iopub.status.idle": "2024-12-30T16:59:52.876777Z",
          "shell.execute_reply": "2024-12-30T16:59:52.876193Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.867521Z"
        },
        "id": "_0EGqbEA2lyz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "tsne = TSNE(n_components=3, n_iter=2000)\n",
        "tsne_embedding = tsne.fit_transform(word_vectors)\n",
        "\n",
        "x, y, z = np.transpose(tsne_embedding)\n",
        "\n",
        "fig = px.scatter_3d(x=x[:200],y=y[:200],z=z[:200],text=sample[:200])\n",
        "fig.update_traces(marker=dict(size=3,line=dict(width=2)),textfont_size=10)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.878683Z",
          "iopub.status.busy": "2024-12-30T16:59:52.878417Z",
          "iopub.status.idle": "2024-12-30T16:59:52.889273Z",
          "shell.execute_reply": "2024-12-30T16:59:52.888545Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.878662Z"
        },
        "id": "ruxbKZBt2lyz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "first_question = ['man', 'woman']\n",
        "#question = ['rem', 'sleep', 'hallucinations', 'paralysis']\n",
        "\n",
        "word_vectors = model.wv[first_question+sample]\n",
        "\n",
        "tsne = TSNE(n_components=3)\n",
        "tsne_embedding = tsne.fit_transform(word_vectors)\n",
        "\n",
        "x, y, z = np.transpose(tsne_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.890313Z",
          "iopub.status.busy": "2024-12-30T16:59:52.890087Z",
          "iopub.status.idle": "2024-12-30T16:59:52.902336Z",
          "shell.execute_reply": "2024-12-30T16:59:52.901559Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.890293Z"
        },
        "id": "Cem4IiRb2lyz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "r = (-20,20)\n",
        "fig = px.scatter_3d(x=x, y=y, z=z, range_x=r, range_y=r, range_z=r, text=first_question + [None] * 500)\n",
        "fig.update_traces(marker=dict(size=3,line=dict(width=2)),textfont_size=10)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.903428Z",
          "iopub.status.busy": "2024-12-30T16:59:52.903158Z",
          "iopub.status.idle": "2024-12-30T16:59:52.915056Z",
          "shell.execute_reply": "2024-12-30T16:59:52.914368Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.903400Z"
        },
        "id": "E795I6ej2lyz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.wv.most_similar('menopause')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.916083Z",
          "iopub.status.busy": "2024-12-30T16:59:52.915796Z",
          "iopub.status.idle": "2024-12-30T16:59:52.927087Z",
          "shell.execute_reply": "2024-12-30T16:59:52.926279Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.916062Z"
        },
        "id": "8RkQLdpv2lyz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "vec = model.wv.get_vector('headache') + (model.wv.get_vector('fever') - model.wv.get_vector('drug'))\n",
        "model.wv.similar_by_vector(vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BMh1vbuc5qp"
      },
      "source": [
        "## Train and evaluate models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFt5KLR-8w3p"
      },
      "source": [
        "#### Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.928108Z",
          "iopub.status.busy": "2024-12-30T16:59:52.927875Z",
          "iopub.status.idle": "2024-12-30T16:59:52.938991Z",
          "shell.execute_reply": "2024-12-30T16:59:52.938276Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.928088Z"
        },
        "id": "ND0M0R633VbB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# class MedDataset(Dataset):\n",
        "#   def __init__(self, instruction, input, output):\n",
        "#     self.instruction = instruction\n",
        "#     self.input = input\n",
        "#     self.output = output\n",
        "\n",
        "#   def __len__(self):\n",
        "#     return len(self.instruction)\n",
        "\n",
        "#   def __getitem__(self, idx):\n",
        "#     sentence = \"<s>[INST] \"+self.instruction[idx]+\". \"+self.input[idx]+\" [/INST] \"+self.output[idx]+\" </s>\"\n",
        "#     return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.940011Z",
          "iopub.status.busy": "2024-12-30T16:59:52.939776Z",
          "iopub.status.idle": "2024-12-30T16:59:52.951321Z",
          "shell.execute_reply": "2024-12-30T16:59:52.950710Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.939981Z"
        },
        "trusted": true,
        "id": "LacKbkPHSsQ-"
      },
      "outputs": [],
      "source": [
        "class MedDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.dataset[idx]\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": example['instruction']},\n",
        "            {\"role\": \"user\", \"content\": example['input']},\n",
        "            {\"role\": \"assistant\", \"content\": example['output']}\n",
        "        ]\n",
        "\n",
        "        prompt = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "\n",
        "        tokens = self.tokenizer(\n",
        "            prompt,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        tokens['labels'] = tokens['input_ids'].clone()\n",
        "        tokens['labels'][tokens['input_ids'] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": tokens['input_ids'].squeeze(),\n",
        "            \"attention_mask\": tokens['attention_mask'].squeeze(),\n",
        "            \"labels\": tokens['labels'].squeeze()\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:52.952410Z",
          "iopub.status.busy": "2024-12-30T16:59:52.952160Z",
          "iopub.status.idle": "2024-12-30T16:59:55.064154Z",
          "shell.execute_reply": "2024-12-30T16:59:55.063424Z",
          "shell.execute_reply.started": "2024-12-30T16:59:52.952378Z"
        },
        "trusted": true,
        "id": "AelKMq1xSsQ-"
      },
      "outputs": [],
      "source": [
        "login(token=\"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\")\n",
        "\n",
        "base_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:55.065221Z",
          "iopub.status.busy": "2024-12-30T16:59:55.064916Z",
          "iopub.status.idle": "2024-12-30T16:59:55.128355Z",
          "shell.execute_reply": "2024-12-30T16:59:55.127665Z",
          "shell.execute_reply.started": "2024-12-30T16:59:55.065191Z"
        },
        "id": "C6gCSyFM7IsG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = MedDataset(ds, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:55.129451Z",
          "iopub.status.busy": "2024-12-30T16:59:55.129104Z",
          "iopub.status.idle": "2024-12-30T16:59:55.142171Z",
          "shell.execute_reply": "2024-12-30T16:59:55.141484Z",
          "shell.execute_reply.started": "2024-12-30T16:59:55.129421Z"
        },
        "id": "RRneCjBj9Lag",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_dataset, val_dataset, test_dataset = random_split(tokenized_dataset, [0.8, 0.1, 0.1])\n",
        "print(f\"Train dataset dimension: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset dimension: {len(val_dataset)}\")\n",
        "print(f\"Test dataset dimension: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzL6yXsGSsQ_"
      },
      "outputs": [],
      "source": [
        "# def convert_to_hf_dataset(med_dataset):\n",
        "#     # Create lists to store all formatted text\n",
        "#     formatted_texts = []\n",
        "\n",
        "#     # Iterate through all items in the original dataset\n",
        "#     for idx in range(len(med_dataset.instruction)):\n",
        "#         # Get the formatted text directly using the dataset's __getitem__\n",
        "#         formatted_text = med_dataset[idx]\n",
        "#         formatted_texts.append(formatted_text)\n",
        "\n",
        "#     # Create a dictionary with the required format\n",
        "#     dataset_dict = {\n",
        "#         'text': formatted_texts\n",
        "#     }\n",
        "\n",
        "#     # Convert to HuggingFace Dataset\n",
        "#     hf_dataset = HFDataset.from_dict(dataset_dict)\n",
        "\n",
        "#     return hf_dataset\n",
        "\n",
        "# hf_dataset = convert_to_hf_dataset(garnachoDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T16:59:55.142987Z",
          "iopub.status.busy": "2024-12-30T16:59:55.142794Z",
          "iopub.status.idle": "2024-12-30T17:00:59.593527Z",
          "shell.execute_reply": "2024-12-30T17:00:59.592693Z",
          "shell.execute_reply.started": "2024-12-30T16:59:55.142969Z"
        },
        "id": "gR4BtF8AHD0I",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "compute_dtype = getattr(torch, \"float16\")\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    bnb_4bit_representation=\"nested\"\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    quantization_config=quant_config,\n",
        "    device_map={\"\": 0},\n",
        "    torch_dtype=torch.float32,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T17:00:59.601461Z",
          "iopub.status.busy": "2024-12-30T17:00:59.601147Z",
          "iopub.status.idle": "2024-12-30T17:00:59.614772Z",
          "shell.execute_reply": "2024-12-30T17:00:59.614099Z",
          "shell.execute_reply.started": "2024-12-30T17:00:59.601433Z"
        },
        "id": "ew98HuwaKW1P",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "peft_params = LoraConfig(\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    r=16,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T17:00:59.615833Z",
          "iopub.status.busy": "2024-12-30T17:00:59.615586Z",
          "iopub.status.idle": "2024-12-30T17:00:59.653074Z",
          "shell.execute_reply": "2024-12-30T17:00:59.652283Z",
          "shell.execute_reply.started": "2024-12-30T17:00:59.615814Z"
        },
        "id": "n8dBHX-j-M1J",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "training_params = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=4,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    eval_strategy=\"steps\",\n",
        "    logging_steps=90,\n",
        "    eval_steps = 90,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    report_to=\"tensorboard\",\n",
        "    gradient_checkpointing=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T17:00:59.654307Z",
          "iopub.status.busy": "2024-12-30T17:00:59.654001Z",
          "iopub.status.idle": "2024-12-30T18:27:02.782730Z",
          "shell.execute_reply": "2024-12-30T18:27:02.781673Z",
          "shell.execute_reply.started": "2024-12-30T17:00:59.654278Z"
        },
        "trusted": true,
        "id": "ARnpWrEFSsQ_"
      },
      "outputs": [],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    peft_config=peft_params,\n",
        "    max_seq_length=256,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_params,\n",
        "    packing=False,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model and tokenizer\n",
        "trainer.save_model(\"./fine-tuned-model\")\n",
        "tokenizer.save_pretrained(\"./fine-tuned-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T18:40:06.102654Z",
          "iopub.status.busy": "2024-12-30T18:40:06.102303Z",
          "iopub.status.idle": "2024-12-30T18:40:06.608165Z",
          "shell.execute_reply": "2024-12-30T18:40:06.607233Z",
          "shell.execute_reply.started": "2024-12-30T18:40:06.102626Z"
        },
        "id": "awbFBy8v5rDM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "trainer.model.save_pretrained(\"model-chatbot-medical-mew\")\n",
        "trainer.tokenizer.save_pretrained(\"model-chatbot-medical-mew\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmC39wTYSsQ_"
      },
      "source": [
        "## Test Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load pre-trained model\n",
        "\n"
      ],
      "metadata": {
        "id": "UwQNV8XLYoLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modificato\n",
        "trained_model = \"model-medical-mew\"\n",
        "question = \"What does low Mobility suggest?\"\n",
        "\n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    bnb_4bit_representation=\"nested\"\n",
        ")\n",
        "\n",
        "login(token=\"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\")\n",
        "\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    trained_model, # change with folder where u have the files\n",
        "    quantization_config=quant_config,\n",
        "    device_map={\"\": 0},\n",
        "    torch_dtype=torch.float32,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(trained_model)"
      ],
      "metadata": {
        "id": "A-XhCQC1YhLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-30T18:43:01.327614Z",
          "iopub.status.busy": "2024-12-30T18:43:01.327258Z",
          "iopub.status.idle": "2024-12-30T18:43:10.136652Z",
          "shell.execute_reply": "2024-12-30T18:43:10.135919Z",
          "shell.execute_reply.started": "2024-12-30T18:43:01.327584Z"
        },
        "trusted": true,
        "id": "NL-rYUPJSsRD"
      },
      "outputs": [],
      "source": [
        "# Modificato\n",
        "# You need to load the dataset first\n",
        "messages = [{\"role\": \"system\", \"content\": instructions[0]},\n",
        "    {\"role\": \"user\", \"content\": question}]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "model_inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**model_inputs, max_new_tokens=128)\n",
        "\n",
        "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(text.split(\"assistant\")[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPKlNEM_sFu0"
      },
      "source": [
        "## Add voice interactivity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QSzEjW2MZrc"
      },
      "source": [
        "### Record Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-30T18:27:02.852003Z",
          "iopub.status.idle": "2024-12-30T18:27:02.852305Z",
          "shell.execute_reply": "2024-12-30T18:27:02.852202Z"
        },
        "id": "7uLKcUMQMeaL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "References:\n",
        "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
        "https://stackoverflow.com/a/18650249\n",
        "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
        "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
        "https://stackoverflow.com/a/49019356\n",
        "\"\"\"\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-30T18:27:02.852822Z",
          "iopub.status.idle": "2024-12-30T18:27:02.853094Z",
          "shell.execute_reply": "2024-12-30T18:27:02.852969Z"
        },
        "id": "oo1ink-uMiYo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "audio, sr = get_audio()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-30T18:27:02.853655Z",
          "iopub.status.idle": "2024-12-30T18:27:02.853877Z",
          "shell.execute_reply": "2024-12-30T18:27:02.853788Z"
        },
        "id": "DaV9sVvZMlCL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "scipy.io.wavfile.write('./recording.wav', sr, audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1k0fMEMNtl2"
      },
      "source": [
        "## Speech to Text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We tried normalize the audio but it will get a worse result. We resample at 16000 because for most speech-focused tasks, 16,000 Hz is optimal (8000 Hz is for telephones that have low bandwith and 44000 is for music)."
      ],
      "metadata": {
        "id": "nhgjYZCRmAzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Resample audio\n",
        "target_sample_rate = 16000\n",
        "audio, sr = librosa.load(\"recording.wav\", sr=None)  # Load with original sampling rate\n",
        "if sr != target_sample_rate:\n",
        "    audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sample_rate)\n",
        "\n",
        "# Save processed audio\n",
        "sf.write(\"processed_audio.wav\", audio, target_sample_rate)\n",
        "\n",
        "print(f\"Preprocessed audio saved as processed_audio.wav\")"
      ],
      "metadata": {
        "id": "rJMq1QMLiDsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-30T18:27:02.854542Z",
          "iopub.status.idle": "2024-12-30T18:27:02.854872Z",
          "shell.execute_reply": "2024-12-30T18:27:02.854712Z"
        },
        "id": "sPQmD992Lpjh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "whis = whisper.load_model(\"base\")\n",
        "\n",
        "# load audio and pad/trim it to fit 30 seconds\n",
        "audio = whisper.load_audio(\"./processed_audio.wav\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "# load audio and pad/trim it to fit 30 seconds\n",
        "fig = plt.figure(figsize=(16,4))\n",
        "plt.plot(audio, linewidth=0.4)\n",
        "plt.ylabel('Amplitude')\n",
        "plt.xlabel('Samples')\n",
        "plt.show()\n",
        "\n",
        "# make log-Mel spectrogram and move to the same device as the model\n",
        "mel = whisper.log_mel_spectrogram(audio).to(whis.device)\n",
        "\n",
        "# Visualize spectrogram\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "plt.pcolormesh(mel.cpu().numpy())\n",
        "plt.colorbar(label='Power [dB]')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.xlabel('Time [10ms]')\n",
        "plt.show()\n",
        "\n",
        "# Use the mel spectrogram to detect the language\n",
        "_, probs = whis.detect_language(mel)\n",
        "lang = max(probs, key=probs.get)\n",
        "\n",
        "# Print result\n",
        "print(f\"Detected language: {lang}, confidence: {probs[lang]}\")\n",
        "\n",
        "# decode the audio\n",
        "options = whisper.DecodingOptions(fp16 = False)\n",
        "result = whisper.decode(whis, mel, options)\n",
        "\n",
        "# print the recognized text\n",
        "print(result.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-30T18:27:02.855837Z",
          "iopub.status.idle": "2024-12-30T18:27:02.856217Z",
          "shell.execute_reply": "2024-12-30T18:27:02.856058Z"
        },
        "id": "La6g7PIIN3yo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dump result text into model\n",
        "inputs = tokenizer(result.text, return_tensors=\"pt\")\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "output = model.generate(**inputs)\n",
        "print(tokenizer.decode(output[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZLo43qaNyqn"
      },
      "source": [
        "## Text to Speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-30T18:27:02.857137Z",
          "iopub.status.idle": "2024-12-30T18:27:02.857562Z",
          "shell.execute_reply": "2024-12-30T18:27:02.857350Z"
        },
        "id": "DVEewwceOF-Y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\n",
        "tacotron2 = tacotron2.to('cuda')\n",
        "tacotron2.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-30T18:27:02.858937Z",
          "iopub.status.idle": "2024-12-30T18:27:02.859342Z",
          "shell.execute_reply": "2024-12-30T18:27:02.859184Z"
        },
        "id": "tcKqPWGXOJz9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp16')\n",
        "waveglow = waveglow.remove_weightnorm(waveglow)\n",
        "waveglow = waveglow.to('cuda')\n",
        "waveglow.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-30T18:27:02.860028Z",
          "iopub.status.idle": "2024-12-30T18:27:02.860393Z",
          "shell.execute_reply": "2024-12-30T18:27:02.860239Z"
        },
        "id": "DlHbL8_YOMON",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Add model response\n",
        "print(tokenizer.decode(output[0]))\n",
        "text = tokenizer.decode(output[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-30T18:27:02.861323Z",
          "iopub.status.idle": "2024-12-30T18:27:02.861724Z",
          "shell.execute_reply": "2024-12-30T18:27:02.861556Z"
        },
        "id": "SYGrvo4YOOBX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\n",
        "sequences, lengths = utils.prepare_input_sequence([text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-30T18:27:02.862526Z",
          "iopub.status.idle": "2024-12-30T18:27:02.862883Z",
          "shell.execute_reply": "2024-12-30T18:27:02.862729Z"
        },
        "id": "oOyIqRq9OQJP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    mel, _, _ = tacotron2.infer(sequences, lengths)\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "plt.pcolormesh(mel[0].cpu().numpy())\n",
        "plt.colorbar(label='Power [dB]')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.xlabel('Time [10ms]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-30T18:27:02.863553Z",
          "iopub.status.idle": "2024-12-30T18:27:02.863999Z",
          "shell.execute_reply": "2024-12-30T18:27:02.863754Z"
        },
        "id": "t-dE1l-dOVwn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    audio = waveglow.infer(mel)\n",
        "audio_numpy = audio[0].data.cpu().numpy()\n",
        "rate = 22050\n",
        "\n",
        "fig = plt.figure(figsize=(16,4))\n",
        "plt.plot(audio_numpy, linewidth=0.4)\n",
        "plt.ylabel('Amplitude')\n",
        "plt.xlabel('Samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-30T18:27:02.864777Z",
          "iopub.status.idle": "2024-12-30T18:27:02.865156Z",
          "shell.execute_reply": "2024-12-30T18:27:02.864977Z"
        },
        "id": "PNwE-1SuObFF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "Audio(audio_numpy, rate=rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s22bSn7_sFu6"
      },
      "source": [
        "## Potential extensions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Better undestand voice, bigger model"
      ],
      "metadata": {
        "id": "G-Cco5tHaU7c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1mPCVNJdGSr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "model_id = \"openai/whisper-large-v3\"\n",
        "\n",
        "model_stp = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
        ")\n",
        "model_stp.to(device)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model_stp,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "result = pipe(\"recording.wav\")\n",
        "print(result[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dump result text into model\n",
        "question = result[\"text\"]\n",
        "print(question)\n",
        "\n",
        "inputs = tokenizer(question, return_tensors=\"pt\")\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "output = model.generate(**inputs)\n",
        "\n",
        "response = tokenizer.decode(output[0])\n",
        "print(response)"
      ],
      "metadata": {
        "id": "VoPSwHQn-vMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/coqui/XTTS-v2\n",
        "\n",
        "from TTS.api import TTS\n",
        "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\")\n",
        "tts.to(device)\n",
        "\n",
        "# generate speech by cloning a voice using default settings\n",
        "tts.tts_to_file(text=response,\n",
        "                file_path=\"output_tts.wav\",\n",
        "                speaker_wav=\"obama_audio.mp3\",\n",
        "                language=\"en\")"
      ],
      "metadata": {
        "id": "_WR31ODmdF5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(\"output_tts.wav\")"
      ],
      "metadata": {
        "id": "IfONRIvNn0fL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30823,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}